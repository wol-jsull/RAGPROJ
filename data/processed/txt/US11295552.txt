US011295552B2 ( 12 ) United States Patent Glaser et al . ( 10 ) Patent No .: ( 45 ) Date of Patent : US 11,295,552 B2 * Apr . 5 , 2022 ( 54 ) MOBILE USER INTERFACE EXTRACTION ( 71 ) Applicant : Grabango Co. , Berkeley , CA ( US ) ( 72 ) Inventors : William Glaser , Berkeley , CA ( US ) ; Brian Van Osdol , Piedmont , CA ( US ) ( 73 ) Assignee : Grabango Co. , Berkeley , CA ( US ) ( * ) Notice : Subject to any disclaim the term of this patent is extended or adjusted under 35 U.S.C. 154 ( b ) by 37 days . This patent is subject to a terminal dis claimer . ( 21 ) Appl . No .: 16 / 803,556 ( 22 ) Filed : Feb. 27 , 2020 ( 65 ) Prior Publication Data US 2020/0195462 A1 Jun . 18 , 2020 Related U.S. Application Data ( 63 ) Continuation of application No. 15 / 644,801 , filed on Jul . 9 , 2017 , now Pat . No. 10,659,247 . ( Continued ) ( 2022.01 ) ( 2006.01 ) ( 2006.01 ) ( 2006.01 ) ( 2020.01 ) ( 2020.01 ) ( Continued ) ( 51 ) Int . Cl . GO6V 40/20 G08B 13/196 H04N 5/225 H04N 7/18 H05B 47/19 H05B 47/125 ( 52 ) U.S. Cl . ??? GO6V 40/20 ( 2022.01 ) ; G06K 9/6232 ( 2013.01 ) ; GOOV 10/245 ( 2022.01 ) ; GO6V 10/40 ( 2022.01 ) ; G06V 20/00 ( 2022.01 ) ; G06V 20/52 ( 2022.01 ) ; G06V 40/10 ( 2022.01 ) ; G08B 13/196 ( 2013.01 ) ; H04L 12/282 ( 2013.01 ) ; H04L 12/2809 ( 2013.01 ) ; H04L 12/2814 ( 2013.01 ) ; H04L 67/12 ( 2013.01 ) ; H04N 5/2252 ( 2013.01 ) ; H04N 5/2257 ( 2013.01 ) ; H04N 7/18 ( 2013.01 ) ; H04N 7/183 ( 2013.01 ) ; H05B 47/105 ( 2020.01 ) ; H05B 47/125 ( 2020.01 ) ; H05B 47/19 ( 2020.01 ) ; GO6V 20/63 ( 2022.01 ) ( 58 ) Field of Classification Search None See application file for complete search history . ( 56 ) References Cited U.S. PATENT DOCUMENTS 5,254,853 A 5,418,567 A 10/1993 Reich 5/1995 Boers et al . ( Continued ) FOREIGN PATENT DOCUMENTS BR WO A2 Al 3/2018 2/2019 OTHER PUBLICATIONS Elizabeth Weise : “ How Amazon's line - less grocery services might really work ” , USATODAY , Dec. 8 , 2016 ( Dec. 8 , 2016 ) , Retrieved from the Internet : URL : https://eu.usatoday.com/story/tech/news/ / 12 / 06 / amazon - go - surveillance - cameras - shopping - grocery supermarket / 95055200 / [ retrieved on Feb. 21 , 2020 ] * the whole document * . Primary Examiner — Delomia L Gilliard ( 74 ) Attorney , Agent , or Firm — Alpine Patents LLC ; Brian Van Osdol ( 57 ) ABSTRACT A system and method for extracting uncoupled information from a user interface output that includes collecting image data ; processing the image data associated with the device interface source ; and exposing the result to the extracted interface representation . Claims , 31 Drawing Sheets Collecting image data Setting extraction configuration of a device interface source identified in the image data , where the extraction configuration includes setting a device position Tracking an image collection position Processing the image data associated with the device interface source into an extracted interface representation according to the extraction configuration and responsive to when the image collection position corresponds to a configured device position of the device interface source Exposing at least one interface to the extracted interface representation S110 S120 S160 S135 S140 US 11,295,552 B2 Page 2 Related U.S. Application Data ( 60 ) Provisional application No. 62 / 360,366 , filed on Jul . , 2016 , provisional application No. 62 / 360,369 , filed on Jul . 9 , 2016 . ( 51 ) Int . Ci . H05B 47/105 G06V 10/40 G06V 10/24 GO6V 20/00 GOOV 20/52 G06V 40/10 G06K 9/62 H04L 6712 H04L 12/28 GO6V 20/62 ( 2020.01 ) ( 2022.01 ) ( 2022.01 ) ( 2022.01 ) ( 2022.01 ) ( 2022.01 ) ( 2022.01 ) ( 2022.01 ) ( 2006.01 ) ( 2022.01 ) ( 56 ) References Cited U.S. PATENT DOCUMENTS 3/1996 Ledger 11/2005 Monroe 2/2006 Krahnstoever et al . 5,502,564 A 6,970,183 B1 6,996,460 B1 7,053,915 B1 7,195,157 B2 7,225,414 B1 7,227,976 B1 7,274,803 B1 7,283,650 B1 7,319,779 B1 7,505,621 B1 7,590,261 B1 7,711,155 B1 7,734,070 B1 7,848,548 B1 7,911,482 B1 7,912,246 B1 7,921,036 B1 7,930,204 B1 7,957,565 B1 7,974,869 B1 7,987,111 B1 8,009,863 B1 8,010,402 B1 8,027,521 B1 8,098,888 B1 8,189,926 B2 8,219,438 B1 8,254,633 B1 8,295,597 B1 8,325,982 B1 8,351,647 B2 8,379,937 B1 8,380,558 B1 8,396,758 B2 8,412,656 B1 8,433,612 B1 8,448,859 B2 8,520,906 B1 8,577,705 B1 8,812,344 B1 9,120,621 B1 9,141,931 B2 9,161,084 B1 9,262,681 B1 9,270,634 B1 9,317,785 B1 9,412,099 B1 9,426,720 B2 9,474,934 B1 9,740,977 B1 9,747,497 B1 9,892,438 B1 9,911,290 B1 1/2008 Mummareddy et al . 5/2006 Jung et al . 3/2007 Swartz et al . 5/2007 Sharma et al . 6/2007 Jung et al . 9/2007 Sharma et al . 10/2007 Sharma et al . 3/2009 Agrawal et al . 9/2009 Mariano et al . 5/2010 Sharma et al . 6/2010 Sharma et al . 12/2010 Moon et al . 3/2011 Mariano et al . 3/2011 Moon et al . 4/2011 Sharma et al . 4/2011 Sharma et al . 6/2011 Sharma et al . 7/2011 Sharma et al . 7/2011 Sharma et al . 8/2011 Sharma et al . 8/2011 Sharma et al . 9/2011 Moon al . 1/2012 Mummareddy et al . 5/2012 Sharma et al . 7/2012 Moon et al . 8/2012 Moon et al . 10/2012 Sharma et al . 12/2012 Moon et al . 1/2013 Sharma et al . 2/2013 Moon et al . 2/2013 Sharma et al . 3/2013 Paradise et al . 4/2013 Baboo et al . 4/2013 Sharma et al . 5/2013 Goncalves et al . 8/2013 Moon et al . 11/2013 Baboo et al . 8/2014 Saurabh et al . 9/2015 Curlander et al . 9/2015 Ackerman 10/2015 Sharma et al . 2/2016 Mishra 2/2016 Gu et al . 4/2016 Moon et al . 8/2016 Tyree 8/2016 Cohn et al . 10/2016 Krueger et al . 8/2017 Moon et al . 8/2017 Sharma et al . 2/2018 Kundu et al . 3/2018 Zalewski et al . 9,948,902 B1 10,055,853 B1 10,083,358 B1 10,127,438 B1 10,133,933 B1 10,134,004 B1 10,198,080 B1 10,198,625 B1 10,217,120 B1 10,262,331 B1 10,282,621 B2 10,296,936 B1 10,339,595 B2 10,347,009 B1 10,354,262 B1 10,387,896 B1 10,474,858 B2 2001/0010541 Al 2002/0122559 Al 2003/02 10340 A1 2003/02 16969 Al 2004/0201754 Al 2004/0260513 Al 2005/0096997 Al 2005/0189411 A1 2006/0032915 Al 2006/0147087 A1 2007/0091177 Al 2007/0146873 Al 2007/0242300 A1 2007/0284440 A1 2008/0226129 Al 2008/0228585 Al 2009/0195648 Al 2010/0020173 A1 2010/0255902 Al 2010/0280956 A1 2010/0295946 A1 2011/0122231 Al 2011/0215147 Al 2012/0019168 A1 2012/0027297 A1 2012/0173351 A1 2013/0103537 A1 2013/0147963 A1 2013/0177201 A1 2013/0215116 A1 2013/0223673 Al 2013/0284806 Al 2013/0290557 Al 2013/0317300 Al 2013/0335571 A1 2013/0342688 Al 2014/0082519 Al 2014/0082610 A1 2014/0129688 Al 2014/0245160 A1 2014/0263631 A1 2014/0265880 A1 2014/0272855 Al 2014/0279191 Al 2014/0285660 A1 2014/0297487 A1 2014/0330408 A1 2014/0363059 Al 2014/0365334 A1 2014/0372957 Al 2015/0012396 Al 2015/0019391 A1 2015/0029339 A1 2015/0039458 A1 2015/0046213 A1 2015/0077787 A1 2015/0077797 Al 2015/0088694 A1 2015/0095189 Al 2015/0097961 Al 2015/0124973 A1 2015/0133190 Al 4/2018 Trundle 8/2018 Fisher et al . 9/2018 Shin et al . 11/2018 Fisher et al . 11/2018 Fisher et al . 11/2018 Liberato , Jr. et al . 2/2019 Worley , III et al . 2/2019 Shin et al . 2/2019 Shin et al . 4/2019 Sharma et al . 5/2019 Glaser et al . 5/2019 Saurabh et al . 7/2019 Glaser et al . 7/2019 Terven et al . 7/2019 Hershey et al . 8/2019 Hershey et al . 11/2019 Davis et al . 8/2001 Fernandez et al . 9/2002 Fay et al . 11/2003 Romanowich 11/2003 Bauer et al . 10/2004 McAlister 12/2004 Fitzpatrick et al . 5/2005 Jain et al . 9/2005 Ostrowski et al . 2/2006 Schwartz 7/2006 Goncalves et al . 4/2007 West et al . 6/2007 Ortyn et al . 10/2007 Inai 12/2007 Birmingham et al . 9/2008 Kundu et al . 9/2008 Duri et al . 8/2009 Thomas et al . 1/2010 Marquart et al . 10/2010 Goldstein et al . 11/2010 Chutorash et al . 11/2010 Reed et al . 5/2011 Fujieda et al . 9/2011 Goncalves 1/2012 Noda et al . 2/2012 Feris et al . 7/2012 Hanson et al . 4/2013 Hewett 6/2013 Henninger et al . 7/2013 Fisher 8/2013 Siddique et al . 8/2013 Davis et al . 10/2013 Margalit 10/2013 Baratz 11/2013 Berci et al . 12/2013 Libal 12/2013 Siu 3/2014 Wang et al . 3/2014 Wang et al . 5/2014 Asenjo et al . 8/2014 Bauer et al . 9/2014 Muniz 9/2014 Taipale et al . 9/2014 Maser et al . 9/2014 Agarwal et al . 9/2014 Jamtgaard et al . 10/2014 Bashkin 11/2014 Rolley 12/2014 Hurewitz 12/2014 Hurewitz 12/2014 Keane et al . 1/2015 Puerini et al . 1/2015 Kumar et al . 1/2015 Kobres et al . 2/2015 Reid 2/2015 Doreswamy et al . 3/2015 Nishimura et al . 3/2015 Kurokawa 3/2015 Ackerman 4/2015 Dharssi et al . 4/2015 Ure et al . 5/2015 Arteaga et al . 5/2015 Fisher et al . US 11,295,552 B2 Page 3 G06T 17/05 ( 56 ) References Cited U.S. PATENT DOCUMENTS 2015/0138383 A1 2015/0154973 Al 2015/0156332 A1 2015/0163412 A1 2015/0227890 A1 2015/0244992 A1 2015/0310601 A1 2015/0327045 Al 2015/0373509 Al 2016/0012379 Al 2016/0019514 Al 2016/0027262 A1 2016/0037135 A1 2016/0100086 Al 2016/0110791 A1 2016/0112608 Al 2016/0132854 A1 2016/0173827 Al 2016/0217388 A1 2016/0224856 A1 2016/0242252 A1 2016/0254864 A1 2016/0270191 A1 2016/0282039 Al 2016/0289964 A1 2016/0321506 A1 2016/0345414 Al 2016/0358312 Al 2017/0032182 A1 2017/0039613 A1 2017/0053171 A1 2017/0108236 A1 2017/0123030 A1 2017/0131781 A1 2017/0161703 A1 2017/0169440 A1 5/2015 Kelley et al . 6/2015 Mckenna et al . 6/2015 Kandregula 6/2015 Holley et al . 8/2015 Bednarek et al . 8/2015 Buehler 10/2015 Rodriguez et al . 11/2015 Chang et al . 12/2015 Wang et al . 1/2016 Iwai 1/2016 Landers et al . 1/2016 Skotty et al . 2/2016 McSheffrey et al . 4/2016 Chien 4/2016 Herring et al . 4/2016 Elensi et al . 5/2016 Singh 6/2016 Dannan et al . 7/2016 Okanohara et al . 8/2016 Park et al . 8/2016 Lim et al . 9/2016 Mueller et al . 9/2016 Ludwig , Jr. et al . 9/2016 Motukuri et al . 10/2016 Engberg 11/2016 Fridental et al . 11/2016 Nolan et al . 12/2016 Kolb et al . 2/2017 Motukuri et al . 2/2017 Kaehler et al . 2/2017 Buehler 4/2017 Guan et al . 5/2017 Hengerer et al . 5/2017 Buban 6/2017 Dodia 6/2017 Dey et al . 2017/0178352 A1 * 2017/0188013 A1 2017/0216667 A1 2017/0278175 A1 2017/0316656 A1 2017/0323376 Al 2017/0332956 Al 2018/0005044 Al 2018/0012080 A1 2018/0107968 A1 2018/0189763 A1 2018/0232796 Al 2018/0240180 A1 2018/0245736 A1 2018/0300553 A1 2018/0322209 A1 2018/0332235 Al 2018/0332236 A1 2018/0373928 A1 2019/0005479 Al 2019/0028643 Al 2019/0043003 Al 2019/0054347 A1 2019/0079591 A1 2019/0114488 A1 2019/0116322 A1 2019/0156273 A1 2019/0156274 Al 2019/0156275 Al 2019/0156276 A1 2019/0156277 Al 2019/0156506 Al 2019/0205933 A1 2019/0333039 Al 2020/0079412 A1 2020/0134590 A1 2020/0160670 A1 2020/0265494 Al 6/2017 Harmsen 6/2017 Presler 8/2017 Garvey et al . 9/2017 Park et al . 11/2017 Chaubard et al . 11/2017 Glaser et al . 11/2017 Bigolin et al . 1/2018 Olson 1/2018 Glaser et al . 4/2018 Wu et al . 7/2018 Olmstead et al . 8/2018 Glaser et al . 8/2018 Glaser et al . 8/2018 Patel 10/2018 Khosla et al . 11/2018 Jin et al . 11/2018 Glaser 11/2018 Glaser et al . 12/2018 Glaser et al . 1/2019 Glaser et al . 1/2019 Oryoji 2/2019 Fisher et al . 2/2019 Saigh et al . 3/2019 Glaser et al . 4/2019 Glazer et al . 4/2019 Holzer et al . 5/2019 Fisher et al . 5/2019 Fisher et al . 5/2019 Fisher et al . 5/2019 Fisher et al . 5/2019 Fisher et al . 5/2019 Fisher et al . 7/2019 Glaser et al . 10/2019 Glaser et al . 3/2020 Ramanathan et al . 4/2020 Glaser et al . 5/2020 Zalewski et al . 8/2020 Glaser et al . * cited by examiner U.S. Patent Apr. 5 , 2022 Sheet 1 of 31 US 11,295,552 B2 Control Interfaces OOO Configuration Monitoring API Web Application Access Interfaces Extracted Interface Representation Data Storage Device Interface Processing Engine Extraction Configuration Imaging System ( s ) Pours PafTx Warning oos BROIL HO www114 82 Device Sources Ø O FIGURE 1 U.S. Patent Apr. 5 , 2022 Sheet 2 of 31 US 11,295,552 B2 S110 S120 S130 S140 Collecting image data S110 Setting extraction configuration of a device interface source identified in the image data Processing the image data associated with the device interface source into an extracted interface representation according to the extraction configuration Exposing at least one interface to the extracted interface representation FIGURE 2 U.S. Patent Apr. 5 , 2022 Sheet 3 of 31 US 11,295,552 B2 FIGURE 3 FIGURE 4 U.S. Patent Apr. 5 , 2022 Sheet 4 of 31 US 11,295,552 B2 FIGURE 5 U.S. Patent Apr. 5 , 2022 Sheet 5 of 31 US 11,295,552 B2 en Front Door Switch V Name Type States locked unlocked FIGURE 6 U.S. Patent Apr. 5 , 2022 Sheet 6 of 31 US 11,295,552 B2 a Initializing a pairing mode Pair Pair Identifying device indicator OFF Pair Setting device position in extraction configuration FIGURE 7 U.S. Patent Apr. 5 , 2022 Sheet 7 of 31 US 11,295,552 B2 S120 S121 S122 S123 S124 S125 Setting extraction configuration Configuring a position of a device interface source Selecting at least one of a set of extraction modes Configuring device interface operating properties Registering visual markers on a device interface source Training extraction of the device interface source FIGURE 8 U.S. Patent Apr. 5 , 2022 Sheet 8 of 31 US 11,295,552 B2 Configuration Visual Data 11 Visual Data t2 Visual Data t3 label : Stovetop type : devicestate - color position : < location > state - monitored : " red channel " O Interface Extraction System red - color : % red - color : % Extracted Interface Rep for t1 Extracted Interface Rep for t2 red - color : % Extracted Interface Rep for t3 FIGURE 9 U.S. Patent Apr. 5 , 2022 Sheet 9 of 31 US 11,295,552 B2 Visual Data TTIR Power Rx / Tx Warning Configuration label : power type : indicator - illuminated position : < location > state - count : 2 Interface Extraction System Device Interface Representations = { RxTx : < data stream of on / off state > , Power ; true , Warning : false , } FIGURE 10 U.S. Patent Apr. 5 , 2022 Sheet 10 of 31 US 11,295,552 B2 Configuration label : Lock type : Indicator - position states : [ { name : " locked " , image : O 0 Visual Data t1 } , [ { name : " unlocked " , image : e } ] Interface Extraction System Visual Data t2 C FIGURE 11 " locked " " unlocked " Extracted Interface Rep for t1 Extracted Interface Rep for t2 U.S. Patent Apr. 5 , 2022 Sheet 11 of 31 US 11,295,552 B2 Visual Data Configuration label : Kitchen Light type : switch position : < location > states : [ " on " , " off " ] state_position : vertical Interface Extraction System Kitchen Light : " off " Extracted Interface Rep FIGURE 12 U.S. Patent Apr. 5 , 2022 Sheet 12 of 31 US 11,295,552 B2 Visual Data B 200 Configuration label : RPM type : dial - rotary position : location > start : { < position > , < angle > , value : 0 } end : { < position > , < angle > , value : 200 } Interface Extraction System Dial : 62 % Motor RPM : 125 Parameterized Interface Rep Classified Interface Rep FIGURE 13 U.S. Patent Apr. 5 , 2022 Sheet 13 of 31 US 11,295,552 B2 Visual Data BROIL d?O Configuration label : Oven type : dial - rotary position : < location > min : 200 max : 501 units : F. indicator : < position > Interface Extraction System Oven : 350 ° F Extracted Interface Rep FIGURE 14 U.S. Patent Apr. 5 , 2022 Sheet 14 of 31 US 11,295,552 B2 % Level indicator % Interface Extraction System Bottle Level = 60 % FIGURE 15 U.S. Patent Apr. 5 , 2022 Sheet 15 of 31 US 11,295,552 B2 Visual Data Today's Special Ham Quiche Configuration label : TodaysSpecial type : text - handwritten position : < location > Interface Extraction System " Ham Quiche " Extracted Interface Rep FIGURE 16 U.S. Patent Apr. 5 , 2022 Sheet 16 of 31 US 11,295,552 B2 Visual Data Configuration label : Frequency segmented characters : type : text - display position : < location > [ 0..9 ] Interface Extraction System frequency : 4508 Extracted Interface Rep FIGURE 17 U.S. Patent Apr. 5 , 2022 Sheet 17 of 31 US 11,295,552 B2 Visual Data O ( ) Configuration label : Ball Count type : Presence - object metric - type : count - current background - sample : object - sample : ) Interface Extraction System BallCount = 3 = . Extracted Interface Rep FIGURE 18 U.S. Patent Apr. 5 , 2022 Sheet 18 of 31 US 11,295,552 B2 Visual Data mummy194 82 BVO - 5000i Device Model Configuration label : Heart Monitor type : Device - model position : < location > Device_model : BVO - 5000i Signals : [ < signal 1 config > , < signal 2 config > , < signal 2 config > ] Interface Extraction System Heart Monitor : { machine_state : state3 , signals : [ signal_1 : 32 , signal_2 : 114 , signal_3 : 82 , ... ] } Extracted Interface Rep FIGURE 19 U.S. Patent Apr. 5 , 2022 Sheet 19 of 31 US 11,295,552 B2 Visual Data Configuration ??? label : Front Door Locking person ] position : location > objects : [ key , lock , type : User - interaction Interface Extraction System Front Door Locking , June 21 , 2017 , < location > Extracted Interface Rep FIGURE 20 U.S. Patent Apr. 5 , 2022 Sheet 20 of 31 US 11,295,552 B2 Providing a visual marker associated with at lest one extraction mode Detecting the visual marker in the image data Lock Extraction Configuration Setting at least part of the extraction configuration based on properties of the visual marker FIGURE 21 U.S. Patent Apr. 5 , 2022 Sheet 21 of 31 US 11,295,552 B2 WHITE Power Warning FIL FIGURE 22A FIGURE 22B FIGURE 22C U.S. Patent Apr. 5 , 2022 Sheet 22 of 31 US 11,295,552 B2 J Car Position = 5ft FIGURE 23 U.S. Patent Apr. 5 , 2022 Sheet 23 of 31 US 11,295,552 B2 .... ? IV Level = 70 % FIGURE 24 U.S. Patent Apr. 5 , 2022 Sheet 24 of 31 US 11,295,552 B2 S125 ::: Locked Unlocked Unlocked Locked + Interface Extraction System FIGURE 25 U.S. Patent Apr. 5 , 2022 Sheet 25 of 31 US 11,295,552 B2 Imaging System Formatting Stage Recognition Stage Classification Stage Integration Stage Analysis Stage Extracted Interface Representations Rendered Interface Representation Parameterized Interface Representation Classified Interface Representation Analyzed Representation FIGURE 26 U.S. Patent Apr. 5 , 2022 Sheet 26 of 31 US 11,295,552 B2 Processing the image data associated with the device interface source into an extracted interface representation according to the extraction configuration Extracting visual data associated with the device interface source Formatting the visual data Extracting the interface output of the device interface source Analyzing the extracted interface output S130 S131 S132 S133 S134 FIGURE 27 U.S. Patent Apr. 5 , 2022 Sheet 27 of 31 US 11,295,552 B2 Formatting Stage Recognition Stage Classification Stage Integration Stage Analysis Stage Extracted Interface Representations ? 200 B Dial Angle : 10. , range : ( -70 . , 70. ) Pressure : 120 psi " normal pressure FIGURE 28 U.S. Patent Apr. 5 , 2022 Sheet 28 of 31 US 11,295,552 B2 S150 Device 1 Device 2 Bed Bed Nurse Device 1 and 2 Captured Device 1 and 2 Lost Worker present : no alert Bed Bed Device 1 regained capture Device 2 still lost Worker exits Alert : " Device 2 has been lost " Worker fixes issue Device 1 and 2 Captured Worker exits with no alert FIGURE 29 U.S. Patent Apr. 5 , 2022 Sheet 29 of 31 US 11,295,552 B2 S110 S120 S160 S135 S140 Collecting image data Setting extraction configuration of a device interface source identified in the image data , where the extraction configuration includes setting a device position Tracking an image collection position Processing the image data associated with the device interface source into an extracted interface representation according to the extraction configuration and responsive to when the image collection position corresponds to a configured device position of the device interface source Exposing at least one interface to the extracted interface representation FIGURE 30 U.S. Patent Apr. 5 , 2022 Sheet 30 of 31 US 11,295,552 B2 orientation location FIGURE 31 U.S. Patent Apr. 5 , 2022 Sheet 31 of 31 US 11,295,552 B2 Control Interfaces OOO Configuration Monitoring API Web Application Captured Device State Interface Analysis Engine Device Interface Configuration Engine Source Processing Device Interface Analysis Stage Integration Stage Classification Stage Recognition Stage Pre - processing Module Formatting Stage Interface Extraction Platform Device Interface Data Storage Imaging System FIGURE 32 MOBILE USER INTERFACE EXTRACTION US 11,295,552 B2 CROSS - REFERENCE TO RELATED APPLICATIONS interface ; This application is a continuation application of U.S. patent application Ser . No. 15 / 644,801 filed on 9 Jul . 2017 , which claims the benefit of U.S. Provisional Application No. / 360,366 , filed on 9 Jul . 2016 , and U.S. Provisional Application No. 62 / 360,369 , filed on 9 Jul . 2016 , all of which are incorporated in their entireties by this reference . TECHNICAL FIELD This invention relates generally to the field of device 15 marker stickers used for configuration and detection ; monitoring , and more specifically to a new and useful system and method for establishing remote integration with a device through a user interface output . output ; BACKGROUND equipment can be costly and risky especially in enterprise 30 based on capture status ; FIG . 15 is a graphical representation of the method used in a dial extraction mode applied to an analog device FIGS . 16 and 17 are graphical representations of the method applied to character extraction ; FIG . 18 is a graphical representation of the method applied to presence extraction ; FIG . 19 is a graphical representation of the method applied to device model extraction ; FIG . 20 is a graphical representation of the method applied to gesture extraction ; process using visual markers ; FIG . 21 is a schematic representation of an exemplary FIGS . 22A - 22C are schematic representations of visual FIG . 23 is a schematic representation of a device aug mentation to convert device interactions into an interface FIG . 24 is an exemplary schematic representation of interface output extraction applied to an IV bag ; FIG . 25 is a schematic representation of training extrac tion of the device interface source ; FIG . 26 is a flowchart representation of a processing FIG . 27 is a detailed flowchart representation of process ing the image data ; FIG . 28 is a flowchart representation of an exemplary processing pipeline for a dial ; FIG . 29 is an exemplary diagram of generating feedback pipeline ; a a FIG . 30 is a flowchart representation of a variation of the method used with a movable imaging device ; FIG . 31 is a schematic representation of a movable imaging device tracking image collection position ; and FIG . 32 is a schematic representation of a system of a preferred embodiment . DESCRIPTION OF THE EMBODIMENTS The following description of the embodiments of the invention is not intended to limit the invention to these embodiments but rather to enable a person skilled in the art to make and use this invention . 1. Overview A system and method for remote integration with a device through a user interface output of a preferred embodiment functions to enable a process for extracting information and data from a device that leverages human accessible and interpretable outputs of the device . The system and method are preferably applicable for applying computer vision and optionally other forms of perceptual sensing to data acqui sition of ambient information in an environment . A limited number of modern devices , products , and systems provide data interfaces , but there are a vast number of devices , products , and systems that expose information as usability affordances to human users- most devices designed for use by a human are generally accompanied by interpretable representations of information . However , even in connected devices , much of this information is not exposed for data method functions to translate such visually exposed infor mational manifestations into device data usable in various applications . Accordingly , the system and method can be applied to modern systems as well as legacy systems . The system and method may be further extended to enable extraction of information from an uncoupled device through any visual and / or audio interface interpretable including There has been a recent trend of creating connected devices or internet of things ( IoT ) devices . Such devices can provide remote access to information . While a connected device can have benefits over traditional , legacy devices , they are also accompanied by other complications and problems . In many cases , gaining the connected device capabilities requires upgrading to a new product . Upgrading situations that depend on the reliability of a device . Even if someone has a connected device , accessing and integrating that device with one or more other systems can be compli- cated . There are also many cases where it may be beneficial to easily monitor some device but installing a conventional sensing solution is too costly or complicated . Thus , there is a need in the device monitoring field to create a new and useful system and method for establishing remote integra tion with a device through a user interface output . This invention provides such a new and useful system and method . BRIEF DESCRIPTION OF THE FIGURES FIG . 1 is a schematic representation of the system and method applied to various types of extraction ; FIG . 2 is a flowchart representation of a first method ; FIGS . 3 and 4 are schematic representations of different types of imaging device configurations ; FIG . 5 is a schematic representation of a variation where the imaging device is directly coupled to the device interface a a source ; FIG . 6 is an exemplary schematic representation of a customization user interface ; FIG . 7 is a schematic representation of an exemplary pairing process ; FIG . 8 is a detailed flowchart representation of configur- ? ing a device interface source ; to physical state extraction ; FIGS . 10 and 11 are graphical representations of the method applied to indicator detection ; FIG . 12 is a graphical representation of the method applied to switch state extraction ; FIGS . 13 and 14 are graphical representations of the method applied to dial extraction ; FIG . 9 is a graphical representation of the method applied 60 integration by the actual devices or system . The system and US 11,295,552 B2 machines for visible machine interfaces . In one preferred embodiment , the system and method utilizes a camera to observe a user interface of a device and convert the user interface output into an extracted interface representation . may all be candidates for being used with some implemen tations of the system and method . Similarly , the introduction of the system and method introduces a paradigm shift in how systems can be designed and the ease with which a digital This extracted interface representation can be a formatted 5 representation of the analog world can be created . This data representation of data from the device . Other embodi ments can additionally or alternatively utilize a microphone to observe audio - based user interface outputs of a device and convert the user interface output into an accessible interface representation . As one potential benefit , the system and method can be used for remotely extracting and exposing the interface output of one or more devices . Remote extraction and visual interface translation enables outside devices to be integrated interface . The device can be unconnected to the system and could be substantially “ uncooperative ” in the sense that integration with the system is passive from the perspective of the outside device . Additionally , the system and method opens up creative use of the system and method without requiring on customized engineering , algorithm creation , or designs of complex costly systems . a As a related potential benefit , the system and method may accommodate a wide variety of types of generic input sources so that the system and method can be adapted to a variety of data collection applications . There are numerous scenarios where it could be beneficial to have the ability to method could offer a set of configuration options such that the system and method could be readily adapted for different applications . Scientists , researchers , engineers , and / or hob byists could utilize the system and method for custom with the system without altering the outside device or its 15 quickly interface with an existing device the system and could be applied to multiple devices and multiple device 20 solutions . For example , an individual may quickly setup a types . For example , legacy equipment , devices with com- plicated data interfaces , connected devices with limited data access , and other devices could be integrated with the system . With remote extraction , the device could remain solution for monitoring and tracking oven usage by extract ing the oven dial position . As another potential benefit , the system and method could be used for collecting historical analytics of a device . Data a operational during system integration , which could be valu- 25 collected through the system and method can synchronize able in industrial situations where equipment downtime is undesired . Furthermore , when applied in industrial settings , well - tested and robust systems can maintain their current designs while still being enhanced for data integration , data to a data warehousing system where the data could be accessed , processed , or used in any suitable way . Because of the adaptability to be used with a variety of devices , the system and method can be a tool for enabling the data which may have economical as well as reliability benefits . 30 logging capabilities of an IoT device to a wide variety of devices regardless of the devices own networking capabili As another potential benefit , the system and method can be used for devices with digital user interfaces and / or analog user interfaces . The system and method could interpret and convert user interface elements such as a segmented display , ties . As another potential benefit , the system and method can be used for detection of a current computing context for use a graphical display , an indicator light , or an analog dial into 35 of one or more devices in an unplanned situation . In other a digital signal . In some cases , a device interface source may not even be traditionally considered a user interface output but may still convey user interpreted information . For example , the angle of a lock switch can convey the binary a words , the use and state of one or more outside devices may be detected and used through the system and method . This can be used for providing more in - depth awareness of current situations for user - facing products , machine devices , state of the lock or the height of a liquid or material in a jar 40 and / or robots . can be a visual representation of content quantity . Accord- ingly , the system and method could be used with a wide variety of device interface sources including but not limited to : a mercury thermometer , a bi - metal thermometer , an LCD Detection of a current computing context could also be particularly applicable when applied with a wearable where the wearable may be used alongside a number of other devices . A mobile variation of the system or method may a thermometer , an amp meter , a watt meter , a tilt sensor , a 45 additionally use automatic enrollment and configuration of shock sensor , a pressure sensor , a flow - rate sensor , a scroll- ing LED display , a light switch , a circuit breaker switch , a door lock latch , an oven dial , the stick shift of a car , a traffic light , an indicator light , rotary dial , a container of fluid , a device interface sources . As an example , a digital assistant running through the wearable device can be exposed to visually presented information and use that for various tasks . Use of the system and method can alleviate dependence on container of particulate solids , a handwritten message board , 50 all outside devices having a digital form of integration with a staging area for objects ( e.g. , outgoing orders at a restau- rant ) , and / or other sources human interpretable outputs information . Additionally , device designs can be customized for visual interpretation by machines in addition to or in place of humans . As a related potential benefit , the system and method could additionally be applied for customized creation of data integration with analog systems . In everyday life , people create systems that have informational significance by how they are perceived by people . As examples , restaurants have 60 systems for conveying what to cook and when orders are ready for customers ; offices have systems for filing docu- ments and the stage in the processing of those documents ; factories and offices use whiteboards to convey information the wearable device . For example , walking up to a regular ATM device could result in automatic logging of an ATM transaction performed by that user . In another example , viewing a parking meter can automatically start extract the time from the parking meter and the personal assistant could use that extracted data in starting a time . In both cases , the system and method could be applied without the ATM device or parking meter being “ smart ” or connected in any way . a As a related potential benefit , the system and method can enable the automatic detection , configuration , and extraction of a device interface source . The system and method could potentially be beneficial to a variety of different use cases . In many respects , the system to employees ; and families develop systems for reminding 65 and method provides a unique technical paradigm shift in each other of chores to name an exemplary set of situations where analog systems convey information . Aspects of these treatment of imaging and interfaces . Visual interface trans lation resulting from the system and method can be used as US 11,295,552 B2 a tool in a wide variety of applications ranging from robust systematized integrations to quick custom integrations . In some sense , the system and method could be used as a passive sensing solution ( i.e. , one that can avoid altering device . It also requires updating existing sensors or devices with the connected smart sensor version . Instantiations of the system and method can be quickly implemented to start extracting data with little adjustment to existing infrastruc operation of the device ) that can be setup and configured 5 ture . For example , an energy meter could be adapted to a ad - hoc without directly interacting with a device interface source . In other words , the system and method may not depend on cooperation by the device interface source . To this end , the system and method can be usable across a wide variety of devices , and the system and method may be used 10 in normalizing information into a common format and data interface . Even if a device is a connected device , it may still be easier and faster to integrate with the connected device using the system and method . The system and method could smart meter with logged data by simply having the system and method integrate with the energy meter as a device interface source . 2. Overview of Types of Extraction The system and method may be used for a variety of different types of extractions including physical state extrac tion , indicator detection , dial extraction , character extrac tion , presence extraction , and / or device model extraction as shown in FIG . 1. These extractions may be used in any additionally be used in adapting legacy equipment to act 15 suitable combination and could include other types of substantially like a connected device . The system and method may be used within various types of products , used in implementing large scale system inte- grations , used in logging device state , used as a tool in extraction . Physical state extraction can comprise a variety of detec tion approaches . Physical state extraction could be based on color , shape , dimensions , area , volume , appearance , pres building customized CV driven solutions , and / or used with 20 ence , position / location , relative position / location , orienta other suitable types of applications . As one application , the system and method can be imple- mented as components of a product such that the product can be specifically designed to leverage visual interface trans- tion , or other properties . For example , physical state extrac tion may be adapted to detect the color of a heating element , and thereby infer its temperature using a black - body radia tion curve . Indicator detection and dial extraction are vari lation . For example , a lamp or lighting fixture can include an 25 eties of physical state extraction . Physical state could addi implementation of the system and method to enable control of the illumination state by an unconnected light switch observed by a camera of the lighting fixture . Other house- hold appliances , computing devices , electronic devices , and tionally be applied to graphic interpretation . For example , a line graph generated by some device could be interpreted by converting the graph into a data set . Indicator detection can be used to detect the binary state the like could similarly use functionality of the system and 30 or n - state classification of an interface element such as an method . As a related application , the system and method may be implemented as capabilities of an imaging device or appli- cation . A digital camera , personal computing device with a application , a surveillance camera , a robot , an automobile , and / or other suitable devices may leverage the system and method to enable device interface extraction for various applications . indicator light , a switch , a circuit breaker , or a lever . Indicator detection can be used for device interfaces with explicit states like a switch , but could also be for natural interfaces like detecting state of a coat on a coat rack or Dial extraction can be used to characterize the position of a dial . The dial may be used in signaling information such as a meter . For example , gas meters and / or temperature dials may show measurements through a dial . The dial may camera , a wearable computer ( e.g. , smart glasses ) , a camera 35 classified states such as a TV on - off state . As another application , the system and method can be 40 alternatively be used as a user input control such as a dial implemented as part of a system integration for various industrial applications . A hospital , manufacturing plant , energy plant , chemical lab , store and / or other suitable envi- ronments could have a system installation applying the used to set the temperature on an oven . Dial extraction can be used for dials aligned along a radial path or a linear path . Character extraction can be used to read or detect alpha / numeric characters . Character extraction can be used with system and method in monitoring operations , events , and 45 digital digit displays ( e.g. , a segmented display ) , graphical data patterns . For example , interface extraction can be used in extracting data from various devices , meters , and control panels . The system and method can be particularly useful in that they can be used with no modification to existing display of text , printed text , or written text . Character extraction can be customized for a resulting data format . Presence extraction can be used to detect object presence changes . Presence extraction can additionally be position infrastructure . A store could use the system and method for 50 aware so that an object may be only detected when in a enabling basic sensing devices throughout the store and collecting data remotely through a surveillance system . For example , scales used in a produce department may display weight through a dial and / or digital display . The system and method may be applied in the store to extract the measured 55 weight of fruit using the existing scale interface . A hospital could apply the system and method in monitoring medical monitoring device status . A factory or industrial plant could use the system and method for retrofitting existing infra- structure for data integration and monitoring . As another application , the system and method may also be implemented as an alternative approach to connected smart sensors . In existing approaches , a device used for logging data is generally produced with a communication module so that it can wirelessly communicate over a net- 65 work . Not only does this add significant cost to each sensing module , but it also means higher power consumption by the particular region . Alternatively , presence extraction could detect the position and / or orientation of an object or person . Presence extraction could additionally include classification of an object . Device model extraction can be used to interpret the user interface output of a stateful system such as a computing device with multiple modes of operation . The system and method can handle adjusting visual interface translation in coordination with a currently detected state of a device . This can be used to extract image data from used applications on a computing device . This can also be used for extracting image data from custom device interfaces like medical devices , self - service kiosks ( e.g. , check - in kiosks , ATM kiosks , etc. ) , control panels , and the like . Such forms of extraction can preferably be configured for a particular device interface source . Device interface sources can be configured as being statically located in some loca US 11,295,552 B2 tion or position . Device interface sources could alternatively be configured for detection within certain regions . In other variations , device interface sources can be configured / pro- cessed on - demand through CV - based object classification image data . The image data can include high resolution video , low resolution video , photographs from distinct points in time , image data from a fixed point of view , image data from an actuating camera , visual spectrum image data , a and / or identification . Device interface sources could addi- 5 infrared image data , 3D depth sensing image data , parallax , tionally be configured for automatic enrollment / configura- tion and / or manual configuration , as well as using permis- sions for restricting capabilities for configuring , processing image data for extraction , and / or accessing data resulting from extraction . 3. Method As shown in FIG . 2 , a method for establishing , uncoupled , remote integration with a device through a user interface output of a preferred embodiment can include collecting lidar , radar , sonar , passive illumination , active illumination , and / or any suitable type of image data . There is preferably at least one imaging device collecting image data . The imaging device is preferably a camera either a video or still camera . The imaging device may collect visual data only , but may additionally collect audio , spatial image data , infrared image data , and / or other forms of imaging data . The imaging device in one variation includes an optical system with a wide - angle field of view , wherein image data S110 , setting extraction configuration of a device 15 generally a given device interface source will be in a interface source identified in the image data S120 , process- ing the image data associated with the device interface source into an extracted interface representation according to the extraction configuration S130 , and exposing at least sub - region that does not fill over fifty percent of the field of view as shown in FIG . 3. In a wide - angle imaging device variation , locating of the device interface source may be a process performed when setting extraction configuration in one access interface to the extracted interface representation 20 block S120 . The imaging device in a second variation S140 . The method functions to enable a user to setup an inter- face extraction system and adapt the interface extraction system for a particular use case where one or more device includes an optical system with a targeted field of view , wherein generally a given device interface source will fill a significant portion of the field of view ( e.g. , greater than twenty - five percent of the field of view ) as shown in FIG . 4 . interface sources undergo user interface translation . Prefer- 25 In a targeted imaging device variation , a device interface ably , the method performs visual interface translation where graphically apparent information concerning the subject ( i.e. , the device interface source ) The method is preferably implemented in connection with an interface extraction source may be specified by simply being present or centered in the field of view . The imaging device may be a stationary imaging device , where the imaging device preferably has a substantially system , which may include a camera to monitor a device and 30 stationary field of view . The imaging device in a stationary a a user application to configure and / or interface with the output of the method . The method is preferably operable on a wide variety of types of extractions including digital and analog interfaces . variation is preferably positioned to observe an area con taining or potentially containing a device of interest . For example , a user mounts or positions a camera at a region be monitored . In some cases , the device interface source and The method here is described primarily from the perspec- 35 the scene are substantially stationary . In another variation , tive of visual interface translation of a single device inter- face source . However , the method can additionally be used for extraction of multiple device interface sources from image data from a single camera , coordinating extraction the scene is stationary . In another variation , the relative position of the imaging device and the device interface source are substantially stationary . For example , the camera and device interface source may be mounted on a moving across multiple imaging devices , performing multiple modes 40 vehicle , but the relative position remains substantially sta variations . of extraction for single device interface sources , and / or other As used herein , a device interface source is an object observable through image data that has some properties or tionary . In some variations , the imaging device may addi tionally be actuated so as to move or be reoriented in different directions . For example , a mounted camera that rotates back and forth . In this variation , actuation position output representing some information . A device interface 45 and changes in orientation / position can be accounted for in source can be an analog device such as an analog thermom- eter , a digital device such as a digital thermometer , a stateful computing device , or other suitable objects that convey some information through their state . A device interface understanding the position of the device interface source . A stationary imaging device can be a mounted at a removed / displaced observation point . This can include mounting the imaging device to a spatially removed location source can additionally include an object or objects that 50 from one or more device interface sources as shown in traditionally are not thought of as a user interface but represent information . For example , the presence of a coat on a coat rack may be indicative of presence of a user and weather conditions and could feasibly be converted as a data feed through the system and method . Block S110 , which includes collecting image data , func- tions to collect video , pictures , or other imagery of a region potentially containing one or more devices . In one variation , the image data may be directly collected from an imaging FIGS . 3 and 4. For example , a camera mounted on a wall opposite an oven could track the dials of the oven . In another variation , the imaging device may be an imaging device directly coupled to or positioned substantially near a device as shown in FIG . 5. For example , the imaging device may include a fixturing system to mount the imaging device alongside the visual interface to be extracted . A custom optical system may be used optically account for a non direct viewing angle . An optical system can facilitate cor device ( e.g. , a camera ) controlled by the interface extraction 60 recting for orientation misalignment of the camera imaging system . In another variation , the imaging data is collected as a data stream or data file . For example , video may be collected from an existing security system and communi- cated to the interface extraction system . plane and a subject plane , which can mitigate distortion and / or improve focus for regions of interest along a plane of a user interface . A Scheimpflug ( e.g. , tilt shift ) optical system can create a wedge - shaped depth of field that can be Collecting image data preferably includes collecting 65 aligned with the subject plane ( e.g. , the plane of a user video data . Collecting image data could alternatively include collecting periodic images or collecting any suitable type of interface display ) . A directly mounted imaging device may be particularly applicable for high reliability applications . US 11,295,552 B2 For example , a directly mounted imaging device may cover the face of a gas meter or pressure valve . In such an implementation , the system may include an output display such that collected data can be mirrored on a display ( as a condition , that particular alarm sound could be detected , and a data object could be updated with a property indicating the detected condition . Block S120 , which includes setting extraction configura data representation and / or an image representation ) , which 5 tion of a device interface source identified in the image data , can be helpful if the imaging device obstructs the view of the actual output In another example , the screen of a medical monitoring device may have an imaging device mounted along one border with a corrective optical system as a described above . The imaging device may alternatively be a movable imaging device . For example , images and video collected from a mobile computing device like a smart phone can be functions to setup a device , interface output , or other con textually - loaded region or object for monitoring . The extrac tion configuration preferably specifies regions of interest in the image data and how the image data is to be converted into a parameterized data format representing information conveyed through the device interface source . The method may enable automatic setting of the extrac tion configuration of a device interface source . For example , one or more types of device interface sources may be objects used as image data . Alternatively , an imaging device inte 15 that can be automatically detected through computer vision grated into a wearable computing device like smart glasses or a body camera can provide the image data . In a movable imaging device , the extraction configuration can be mapped to an image collection position . techniques of object detection / classification and then enrolled for extraction . In an instance of automatically setting extraction configuration , the method can include detecting a type of device interface source in the image data In particular for the movable imaging devices but simi- 20 through object recognition , and automatically setting the larly applicable for other types of imaging devices , user accounts may be associated with an imaging device . When the method is implemented as a platform for distributed visual interface extraction , permissions may be used for extraction configuration of the detected device interface source according to the type of device interface source . Alternatively , parts of the configuration process may be performed or augmented through user input . In one imple sharing and cooperative collection of image data . In some 25 mentation , a user can use a user interface to configure cases , image data collected by one user may be used for visual interface extraction of data viewable by a second user and not necessarily the user account that provided the image data . extraction of the device interface source as shown in FIG . 6 . In an instance involving manual setting of extraction con figuration , the method can include receiving manual con figuration input through a coupled management application . The above imaging device may additionally be used in an 30 The user interface may display an image from the imaging imaging device network that collects image data from mul tiple imaging devices . Preferably , collecting image data occurs from a variety of capture points wherein collecting points in an environment . The set of capture points can include overlapping and / or non - overlapping views of moni tored regions in an environment . The set of capture points device and “ add ” a device for extraction by specifying a position of a device and providing information on how the interface should be interpreted . In yet another variation , augmentation to the device interface source can enhance The setting of extraction configuration may be performed alongside image data collection . For example , actual image data can be used in locating the region of the device interface source . The extraction configuration may alternatively be set image data includes collecting image data from multiple 35 monitoring of a device interface source . image capture devices ( e.g. , cameras ) distributed at distinct a can additionally establish a high - density imaging system 40 independent of image data collection . In one variation , a within the environment . The image data preferably substan- tially covers a continuous region . However , the collected image data may alternatively constitute non - continuous regions with holes , gaps , uninspected regions , and / or non- user interface or configuration file / script may be used in setting the properties of an extraction configuration inde pendent of or without real - time use of image data . In yet another variation , the configuration may be set contiguous regions . The imaging device network may be 45 through a guided process during a pairing mode of the used for monitoring distinct regions and distinct devices . The imaging devices may alternatively have overlapping fields of view and , in some cases , monitor the same device . Redundant observation of a device interface can be used to system . In a guided process , method may include initializing a pairing mode , identifying a device indicator in the image data during the pairing mode , and associating a device position property of the extraction configuration to a region provide enhanced reliability in visual interface extraction , 50 indicated by the device indicator as shown in FIG . 7. The where one imaging device can provide visual observation of a device interface source when another imaging device is blocked . An imaging device network may additionally be used in tracking a device interface source through an envi- interface extraction system can preferably be set or requested to enter the pairing mode by a user , and during the pairing mode the system preferably operates to facilitate the setting of extraction configuration . Two preferred variations ronment while periodically or continuously performing 55 of identifying of a device indicator can include detecting a a visual interface extraction . The method may additionally be modified to work with auditory interface elements wherein collecting image data may include collecting audio - visual data . Alternatively , col- user gesture and detecting a visual marker ( e.g. , a QR code ) . Other forms of marking a region could alternatively be used . In the variation of detecting a user gesture as a device indicator , a user may perform some detectable gesture that lection of audio may be performed separately from the 60 is detectable through computer vision . Gestures could be imaging devices . A device may generate distinct sounds to signal different information . These sounds may be charac- terized by different tone patterns . Auditory data could be collected through a microphone . The auditory sounds can be static gestures ( e.g. , thumbs up ) or action gestures ( e.g. , swiping to the left ) . The user preferably performs that gesture in proximity or against the device interface source . For example , a user may be direct to place their hand , palm processed to convert the auditory sounds into an extracted 65 open in front of the device interface source of interest and interface representation . For example , a device may emit a particular alarm sound when a sensed metric satisfies some a count down using their fingers . The interface extraction system can produce signaling beeps for each count and then US 11,295,552 B2 confirmation beep when that region is configured for inter- face extraction . Any suitable framework for gestures may be In the variation of detecting a visual marker , a visual used . ( CNN ) , statistical machine learning , or other suitable approaches . Neural networks or CNNS such as Fast regional - CNN ( r - CNN ) , Faster R - CNN , Mask R - CNN , and / or other neural network variations and implementations can marker may be used to indicate a candidate device interface 5 be executed as computer vision driven object classification source . The visual marker could be statically fixed to the device interface source . Alternatively , the visual marker could be a card or some object that a user temporarily positions next to the device interface source . As described processes . Image feature extraction and classification is an additional or alternative approach , which may use processes like visual words , constellation of feature classification , and bag - of - words classification processes . These and other clas below , visual markers can additionally or alternatively be 10 sification techniques can include use of scale - invariant fea used in various approaches to configuration . In one variation the initializing of a pairing mode may additionally include setting the pairing mode for a particular type of extraction , which in some variations may simplify ture transform ( SIFT ) , speeded up robust features ( SURF ) , various feature extraction techniques , cascade classifiers , Naive - Bayes , support vector machines , and / or other suitable techniques . Object classification and detection models can the configuration process to identifying the region / location 15 be trained on particular types of device interface sources . of the device interface source . For example , a user could turn on a dial pairing mode on an interface extraction system , then perform some action to mark the device interface source of interest , and then that device interface source can be configured for extraction as a dial . In some instances , the interface extraction system may come pre - configured for extraction of one or more device interface sources , in which case the method may not neces- sitate explicit setting of extraction configuration . As one Receiving selection of a position functions to have the region set through user input or other forms of input . The selection of the position in one variation can involve user input indicating a position and / or region to associate with a device interface source . In one variation , selection of the position of the device interface source can be received through a graphical user interface . A user application could display the image data and provide a user interface tool for selection of one or more exemplary use - case , a product using an interface extraction 25 regions of a device interface source . Such position specifi system may be pre - configured during production to recog- nize and respond to one or more user interfaces . For example , a lamp may come with an imaging device to alter illumination state in coordination with a paired light switch visible in the field of view . As shown in FIG . 8 , configuring a device interface source can include configuring a position of a device interface source S121 , selecting least one of a set of extraction modes S122 , and / or configuring device interface operating cation may alternatively be specified programmatically through an application programming interface ( API ) or other suitable type of interface . In another variation , selection of the position can be achieved through some interaction during a pairing mode . The pairing mode can be a special mode that when engaged , device interface sources can be identified , located , enrolled , and at least partially configured . Various forms of interac tions may be supported for pairing such as a user interaction properties S123 . Configuring a device interface source may 35 variation and a visual marker variation . a additionally include registering visual markers on a device interface source S124 , and , in some variations , configuring a device interface source may additionally include training extraction of the device interface source S125 . Depending In a user interaction variation , a pairing mode can include initiating the paring mode in the interface extraction system ( e.g. , the imaging device ) ; detecting a user interaction in a region of the image data ; and setting the position of the on the application , any suitable combination of the processes 40 device interface source relative to the region of the user S121 , S122 , S123 , S124 , and / or S125 may be used . Block S121 , which includes configuring a position of a device interface source , functions to indicate one or more locations in the image data associated with the device interaction . For example , during a pairing mode , a user could toggle a light switch multiple times to select the region of the light switch as a device interface source . The inter action could additionally be used in training or specifying interface source . Configuring position can set a location and 45 other properties . In the light switch example , toggling the region of image data . Additionally , configuring position can include setting orientation of the device interface source . Two potential approaches to configuring a position of a device interface source S121 can include detecting a device of a position . Detecting a device interface source in the image data functions to use computer vision to recognize a type of device interface source . Detection of a device interface switch . light switch can indicate the different states of the light a In a visual marker variation , a pairing mode can include initiating the paring mode in the interface extraction system region of the visual marker in the image data ; and setting the position of a device interface source relative to the visual marker . The visual marker may explicitly set the bounds of an inspected region for a device interface source . The visual a interface source in the image data and / or receiving selection 50 ( e.g. , the imaging device ) ; identifying a visual marker and source will preferably additionally identify a position and 55 marker may alternatively be used as user selection of one of region in the image data . In some variations , detecting a device interface may additionally be used in accessing preconfigured default extraction configuration for that type of device interface source . For example , detecting a light switch can automatically result in having basic extraction 60 configuration enabled for that light switch . In a related variation , visual marker may be automatically detected using computer vision and used in setting position and possibly other extraction configuration properties . a set of possible device interface sources . For example , the visual marker may be placed somewhere in the field of view , and then object detection of viable device using computer vision techniques can be used . In the variation where the imaging device is movable , configuring position of the device can additionally include setting image collection position , which functions to detect the location and / or orientation of the imaging device when viewing the device interface source . The image collection Various techniques may be employed in object detection 65 position may additionally use distance estimation and scene and classification of a device interface source such as a “ bag of features ” approach , convolutional neural networks analysis to understand the positioning of the device interface source , which can be used in detecting what image data US 11,295,552 B2 collected from other perspectives could be candidates for observing the device interface source . The image collection position can include a global location , a local position ( e.g. , relative to a particular environment ) , structural position properties such as setting the value range and metrics of signal dial . Other varieties may have complex operating properties such as device model extraction , which may include multiple state - machines and multiple child device ( e.g. , room or location in a building or facility ) , and / or other 5 interface source extractions as part of the operating property forms location information . Orientation , direction , and / or information pertaining to the field of view of the imaging device may additionally be included in the image collection position information . A movable camera will preferably for one computing device . Configuring of operating properties can be manually configured , pre - configured to default values , and / or have automatic configuration . Automatic configuration may use have a location service ( e.g. , GPS , Wi - Fi positioning ser- 10 computer vision in interpreting and setting one or more vice , etc. ) and / or an inertial measurement unit ( e.g. , three- axis accelerometer , three - axis gyroscope , and magnetom- eter ) where location and orientation data can be stored as the image collection position . operating properties . In the example , of the dial gauge above , the range of values indicated by the dial could be detected through optical character recognition , automati cally setting the value range . When being set through at least Selecting at least one of a set of extraction modes S122 15 partial user configuration , the visual rendering of the image can be used when the method supports a plurality of types of extractions . The type of extraction can be set to customize the visual interface translation for the particular device interface source . The set of extraction modes can include data can be augmented with a rendering that visually rep resents how the device interface source will be monitored . For example , during setting of operating properties , a sub stantially real - time extracted interface representation can be physical state detection mode , an indicator detection mode , 20 generated from image data . a dial extraction mode , a switch extraction mode , a character extraction mode , a presence extraction mode , a device model extraction mode , and / or other suitable modes of extraction . Different implementations may expose different levels of operating properties . Advanced properties may expose con figuration of low - level interface modeling properties . Higher - level generalized configuration can provide general The different extraction modes may have more granular 25 ized operating properties for common classes of device types of extractions . For example , the physical state detec- tion mode represents one class of extraction modes that can include the indicator detection mode and the dial extraction mode . In the case of a device model extraction mode , a interface sources . Such generalized operating properties may involve selection of a class of device interface source and then setting of a small set of basic properties . For example , a dial input may be selected for an oven where the a particular device model is preferably specified since a device 30 temperature range are configurable properties so that based model extraction mode is generally customized to a particu- lar type of stateful device . The different extraction modes will preferably define different operating parameters in block S123 and may offer configuration options specific to on the angle a set temperature can be extracted . The method may additionally expose a programmatic layer to enable third parties to build out custom logic for a device interface source wherein the operating properties may be defined in a a the particular extraction mode . The different extraction 35 configuration file ( s ) or application . modes will additionally trigger correspondingly different processing routines in block S130 . Each position of a device interface source is preferably mapped at least one type of extraction . In some variations , As described below , the processing of the image data to generate an extracted interface representation may involve multiple processing stages of formatting , recognition , clas sification , analysis , and / or integration . Operating properties a single device interface source may have multiple types of 40 may be configurable for each of these stages or one of these extractions configured . In one variation , selection of an extraction mode is specified by received user input indicat- ing one or more types of extraction . In another variation , the method may use computer vision based object detection , stages . In some variations , operating properties are not configurable by a user and are pre - configured or automati cally set . As examples of basic operating properties that may apply visual marker detection , or other classification approaches to 45 to many types of extraction , setting operating properties can automatically set the extraction mode . In some cases , multiple types of extraction may be set for an overlapping region of the image data . Some devices may communicate information through a variety of mechanisms , include aspects such as setting units and setting valid data values , which functions to set the labeling and formatting of the data . Units can be used to label or indicate the meaning of the data . Valid data values can set the space of values and the method can isolate this information through different 50 expected . This can include setting number value ranges , types of extractions . For example , a display may display a three - digit number and indicate another property by illumi- nating the display in one of three different colors character extraction and color - based physical state extraction can be used simultaneously on that one device . Block S123 , which includes configuring device interface operating properties , functions to set or define parameters that characterize the way a device interface source changes and should be interpreted . The different types of extraction expected numeral / character output space , value formatting , and / or other properties of valid or likely output from the device interface source . In some cases , the method can support setting of expected operating state to bias the detection to normal operating conditions or conversely make more sensitive to certain conditions . Additionally , the tem poral properties of detection and processing such as sam pling frequency may be set . Other basic operating properties can include setting different actions or ways of treating . preferably have different sets of operating properties that 60 Processing and analysis logic may additionally be config characterize the components , mechanics , and models for how a particular type of device interface source operates . Different sets of operating properties may be applicable for physical state extraction , indicator detection , dial extrac- tion , character extraction , presence extraction , device model 65 extraction , and / or any other types or sub - classes of interface extraction . Some varieties may have a small set of operating urable such that customized logic can be applied on basic parameterized interface representations . Different types of extractions may use different operating properties for defin ing the mechanics of a particular device . Configuring operating properties for a form of physical state extraction can be used to set the sensed properties of one or more objects in a particular region . Physical state US 11,295,552 B2 extraction can include many various forms of state extrac- tion including detecting general physical state properties , indicator detection , forms of dial extraction , forms of switch or mechanism extraction , presence extraction , and others . In some cases , a dial may be a continuous dial that can rotate continuously such as a clock hand . A sampling rate may be set based on the maximum rate at which the dial can rotate so that the method can monitor the continuous dial's General physical state properties may include setting 5 progress . The starting position could be initiated when setting up the continuous dial so that subsequent rotation can operating properties that characterize one or more physical attributes of the visual appearance of an object or objects can be monitored in association with a device interface source such as color , size , shape , dimensions , area , volume , appear- be tracked . In some cases , a dial extraction may be configured to indicate progress of an element between at least two posi ance , or other properties . As shown in FIG . 9 , a user may 10 tions . Other forms of extraction may enable extraction of configure a stove top to be monitored based on the color of the burners . Note that the color range may extend into the infrared in order to better capture color data that can effectively be converted into temperature . Infrared imaging position in multiple dimensions . As shown in FIG . 15 , the content level in a container could be treated like a dial with the content level acting as the indicator between the top and bottom positions , and the transfer function being propor a devices can be used for monitoring object temperature , 15 tional to the area cross section at each gradation . This could melting of solid , evaporation of a liquid , leaking of a pressurized gas or liquid , paint drying determination , mois- ture , and / or other aspects . As shown in FIG . 10 , configuring operating properties for be used for bottles and / or other containers , where the contents can be treated as a linear indicator along a vertical scale . Deeper operating property customization , such as defining a mapping between indicator position and bottle indicator detection can include specifying the number of 20 volume , can enable extraction of volumes . indicated states and classifying at least a subset of the indicated states . The type of indicator could be another property such as illuminated indicator , color indicator , posi- tion indicator , shape indicator , and the like . For example , a As shown in FIG . 16 , character extraction functions to convert displayed , written , or printed alphanumeric charac ters into computer readable text data . Configuring character extraction can include setting the region where text is user may note that an LED indicator light has two states and 25 extracted and optionally properties of the text . The proper that the current state is “ off ” . Image data can be collected and associated with the “ off ” state . In one variation , image data may be stored and used for visual comparison . Alter- natively , a set of image processing routines may be per- ties of the text can include valid characters ( e.g. , only numbers or only letters A - F ) , the number of characters , the font or format of the characters , the number of lines , the orientation of the characters , and / or other properties . As formed to characterize the state algorithmically . The user 30 shown in FIG . 17 , a seven - segment numerical display could may note that the other state is “ on ” . The user may option- ally activate the LED indicator light so that image data can be collected on that state . Similarly , an analog indicator such as a light switch or a lock knob could be configured with be configured to convert the display into numbers represent ing the current frequency setting of the device . As shown in FIG . 18 , configuring presence extraction can involve setting a background region for detecting presence multiple positional states being configured as shown in FIG . 35 and setting the conditions for a presence event . Presence 11. Any number of states can be configured for an indicator . An indicator can additionally be used as a form of a switch extraction more , which functions to detect the posi- tional state of a mechanism with two or more stable state extraction can be used to detect when any object enters a space . Presence can be detected by comparing the image data to image data of the background region . The back ground may be initially set by capturing the image data of configurations as shown in FIG . 12. The switch can be a 40 the background region with no foreground objects . The light switch , a lever , or other suitable mechanism . Switch extraction can have similarities to indicator extraction and / or dial extraction . Preferably , the setting the operating proper- ties includes setting the number of possible states and the method can additionally build an understanding of the background region over time . For example , the method could learn the visual appearance of the background region under different lighting conditions . Conditions for a pres respective labels or interpretation of each state . In some 45 ence event can be a set of conditions based on properties of cases , some simple state machine logic may be configured as an operating property to specify the possible transitions between states . As shown in FIG . 13 , configuring operating properties for foreground objects . Properties of foreground objects can relate to the size of the object , the shape of the object , the visual texture of the object , the color of the object , or general appearance of the object . In one implementation , image dial extraction can include specifying the minimum range of 50 recognition is performed on a foreground object . Presence the dial , a maximum range of the dial , intermediary values , the type of indicator , the path of the indicator , and / or other aspects . The intermediary values can be used to show how values vary along the path of the indicator . Values can vary extraction can be set to indicate if one or more types of objects are present . In one variation , configuring presence extraction can include setting the set of detected object classifications . The set of object classifications may be linearly , logarithmically , exponentially , or with any suitable 55 selected from a set of possible object classifications . In one transfer function . The path of the indicator can be an are for a radial dial . The path of the indicator may alternatively be linear for a linear dial such as a thermometer . When the dial device is actively used as a user interface output , the variation , a customized deep learning neural network model for object classification of a set of objects may be used . Facial or biometric classifications can additionally be used in detecting presence . Presence extraction may alternatively indicator is preferably visually distinct . When the dial device 60 be configured to count the number of objects present cur is used primarily as a user input , then the indicator may be indicated through the visual appearance of a knob or dial . For example , an oven dial may have a slight protrusion used to indicate its position ( as well as serving as a grip for the rently or over time . Presence extraction can additionally be used with other forms of physical state detection such that color profiles , size , shape , and / or other detectable attributes can be collected in addition to or in response to detection of user ) . In another variation , the dial may be reversed where 65 some object presence . the indicator is fixed , and the value rotates as in the oven In some cases , presence detection may be applied in combination with other types of extraction and / or other data example shown in FIG . 14 . US 11,295,552 B2 collection processes . For example , different tasks or pro- cesses may be conditional on detecting ( or not detecting ) one or more objects . In this way presence may provide context to other forms of data extraction and processes . For at a particular position . In one exemplary application , the gesture of locking a door lock with a key may be a detectable gesture . The physical action of locking may be detectable through computer vision . Alternatively , gesture detection example , changes in a light switch may be conditionally 5 could be composed of detecting presence of a person , a key , extracted when a human is present in the image data . Presence detection can additionally be applied in a mov- able device variation , where the location of a device inter- face source may not be known or static . Presence detection and the lock within some threshold of near proximity and / or making contact . Block S124 , which includes registering visual markers on a device interface source , functions to use visual markers in can be configured such that block S130 can enable detecting 10 facilitating configuration . The visual markers could be stick one or more configured objects and , in response , collecting data ( i.e. , contextual data ) . Collecting data in one variation can be performing some type of interface extraction . The interface extraction can be set through extraction configu- ers , marks , or attachments that can be physically added to the device or otherwise augment how the device is per ceived . The visual markers are preferably visually distinct and made of a distinguishable color and / or graphical pattern . ration that is associated with the object or objects . For 15 Additionally , the visual markers could have a machine example , character extraction can be configured to extract the time displayed on a parking meter when the parking meter object is detected . Collecting data in another variation can include recording of metadata at the time of detecting readable code such as a QR code or a barcode . The machine readable code is preferably set to an identifier . The identifier can be used to indicate different things such as the purpose and meaning of the marker and how it should relate to the at least one type of object and associating the metadata 20 extracting information . with the extracted interface representation . Metadata may include location , position , position of the object , time of day , audio data , application state of a device , and / or other forms of data collectable from the imaging device , an application / Two preferred variations of using visual markers can include using the visual markers in specifying at least a portion of extraction configuration and / or using positioning of visual markers in setting at least a portion of operating device in connection with the interface extraction system , a 25 properties . As discussed above , a pairing mode is another third - party service , and / or any suitable source . In one example , presence extraction can be used to detect car keys and to record geographic location upon detection of the car keys . In this way , a user could configure a movable camera potential application of visual markers , but they may alter natively be used in other ways . In a variation where visual markers are used to specify at least a portion of extraction configuration , visual markers ( e.g. , a wearable camera ) to track the last location where the 30 may be placed on different device interface sources where car keys were seen . As shown in FIG . 19 , configuring operating properties of a device model extraction may include setting device model options . In one variation , a number of device models are the visual markers indicate extraction configuration . Detec tion of a visual marker can indicate position of a device interface source but may additionally indicate an extraction mode . Accordingly , the method can include providing a provided for interpreting stateful computing devices and 35 visual marker associated with at least one extraction mode , their respective device states . In this option , configuring the operating properties of a device model may be simply selecting one of the device models and selecting data extraction information options that are of interest for a detecting the visual marker in the image data and setting at least part of the extraction configuration based on properties of the visual marker , wherein position , extraction mode , and / or device interface operating properties can be set as particular application . Alternatively , a device model can be 40 shown in FIG . 21. In one variation , the visual markers may specified through a device model profile , application , or other programmatic specification of the device states and directions on how to extract information from the image data during different device states . As a stateful device , a device visually represent an identifier . The identifier can be used in accessing extraction configuration associated with that iden tifier . The identifier can be unique such that the extraction configuration can be uniquely customized . The identifier interface source may present different information in differ- 45 may alternatively not be unique where it can reference an ent ways in different conditions . Device model extraction will generally use multiple variations of the above forms of extraction in setting how to extract information data from image data . For example , character recognition in combi- extraction configuration that can be shared across multiple device interface sources . Alternatively , the visual markers may represent some visually encoded message that embeds the extraction configuration properties . In this variation , the nation with indicator detection may be used to extract 50 visual marker may be used without needing access to a different data feeds of information where it is intelligently extracted and associated with a data feed based on detected indicators . Audio interface signals may additionally be used . As shown in FIG . 20 , configuring gesture detection can a database of associations . In this variation , common extrac tion configurations may be associated with visual markers that can then be positioned or attached to different device interface sources of interest . Image data containing that involve selecting a detectable gesture and / or gesture condi- 55 capture the visual marker will then be automatically pro tions . In one variation , a gesture extraction mode can be a basic form of presence detection where a gesture is gener- alized to proximity of two or more detectable objects . Alternatively , particular actions may be trained and detect- cessed using the extraction configuration . In another variation , visual markers may be used in marking different aspects to assist in the extraction of information . This variation preferably leverages different able a computer vision model . Gestures may be actively 60 visual markers to augment a device interface source so as to performed actions for input , but could alternatively be natural actions that can be interpreted as a gesture . Hand gesture , facial expressions , or other actions can be detectable forms of gestures . Custom gestures , actions , or events could make it more easily or reliably interpreted . This variation may include providing a set of visual markers , such that the combined positioning of the set of visual markers as detected in the image data at least partially define extraction be trained and used for a particular gesture extraction . 65 configuration of the device interface source . Visual markers Gesture detection may be reactive to presence detection . However , gestures may alternatively be linked to detection may have attributes to specifically configure particular aspects of extraction configuration . Different types of visual US 11,295,552 B2 markers may be used to configure the position of a device interface source , the type of extraction , and operating prop- erties as shown in FIGS . 22A - C . A position setting visual marker may be used to mark as shown in FIG . 25. Training could be performed during an initialization process , but may additionally or alternatively be performed during operation . Training preferably involves collecting a training set of image data and generating a where a device interface source is located and possibly set 5 model for associating the image data of a device interface a the dimensions of associated image data . A position visual marker may be a box that can be placed to circumscribe a device interface source . Other systems of a visual marker could alternatively be used . of extraction to be used . Element visual markers may be used to characterize the operating properties of the device interface source . source with various values . The training may be beneficial in scenarios where the device interface source does not per fectly map to one of the available types of extractions . Training may be an alternative approach to configuring . For show the imaging device a number of possible dial positions and input their associated values . The interface extraction system can alert the user when enough samples are col a An identifier on the visual marker may indicate the type 10 example , instead of setting up how a dial works , a user could a Operating property visual markers may be used to specify different operating properties . The positioning of a property is lected . The interface extraction system does not need to have visual marker can convey some information used in setting an operating property , the type or label of an operating property visual marker may additionally be used . For example , a min - value visual marker and max - value visual a samples for a full set of possible values because , the method could interpolate the visual detection of un - trained values . The training and automatic detection of device state can be performed using computer vision , deep learning , neural marker may set the range of a dial . An operating property 20 networks , and / or other suitable forms of machine intelli visual marker may additionally include variable fields where information can be included to set variables . These may be used in combination to set multiple operating properties . For example , dial - based visual markers may visually mark the gence . Block S130 , which includes processing the image data associated with the device interface ource into an extracted interface representation according to the extraction configu minimum value , intermediary values , maximum value , ori- 25 ration , functions to interpret the device interface source . As face source . The visual markers can act as a physical 30 source . In some cases , this may result in multiple data entation of an indicator , path of the indicator , and / or any suitable operation property . Once placed , visual markers are preferably detected and used to automatically configure aspects of the device inter approach to normalizing detection of different types of devices . They may additionally be used to artificially make particular device ( s ) be perceived as a different type of device . For example , dial extreme markers can be placed on of a car to convert a car pulling into a garage as a progress bar dial as shown in FIG . 23 . In another exemplary application , the method could be applied to an IV bag . The IV bag could be a common IV bag discussed , one or more device interface sources can be extracted simultaneously from the image data . Additionally , one device interface source may have one or more types of extraction applied to the image data of that device interface streams of extracted interface representation . An extracted interface representation is preferably a data object that reflects the state of the device . Various embodiments of the such as a rendered interface representation , a parameterized interface representation , a classified interface representation , and / or any suitable analyzed representation . A rendered interface representation can be a virtual ren a cone and wall of a garage with another marker on the front 35 method may provide one or more types of representations such as a drip or pump system , which enables existing 40 dering or an image - based rendering of the interface . The equipment to be used . The IV bag may be augmented to enhance the fluid level presence . In one variation , a light could be used to illuminate the fluid to enhance detecting its level . In another variation shown in FIG . 24 , a graphical rendered interface representation can provide a visual rep resentation . An image - based rendering can be a formatted version of the device interface source as captured in the image data . An image - based rendering may be saved and pattern could be place in the background . The optical 45 used to provide the base truth of the state of device interface disruption of the pattern caused by the fluid could be differentiated from disruption caused by just the bag , and the fluid level could be derived from this observation . Visual markers could similarly be applied to other appli- source . A virtual rendering can be a simulated visual repre sentation that can be constructed from a parameterized or classified interface representation . A rendered visual repre sentation in some applications can be streamed or provided a cations of monitoring liquid contents of an at least semi- 50 as a visual representation to accompany a machine transla transparent container . For example , bottles of liquid could similar be monitored . A visual marker strip could be adhered to the back of the bottle . Alternatively , a visual marker background could be positioned such that the bottles of tion of the information . A parameterized interface representation can be a machine - readable representation of the interface . In some variations , an initial form of parameterized interface repre interest are the visual marker background and the imaging 55 sentation can be a conversion of image data of a device device . The visual graphical pattern in this variation may be a graduated pattern with continuous or discrete segments of different identifiable levels . The level of the liquid can correspond to marked liquid levels based on the detection of a graduated pattern . In a similar variation that does not utilize augmentation the method could learn the background visual representation and use a similar approach to optical disruption to identify the fluid level . interface source to a data representation . This can include reducing the components of the interface into its base components . An example for a dial device interface source would be the dial angle and position relative to the dial range . Those parameterized representations of the base components may then be converted to a classified interface representation . A classified interface representation is pref erably achieved through characterizing informational data from a base parameterized representation . In some cases , Block S125 , which includes training extraction of the 65 processing of the image data may bypass any intermediary device interface source , functions to use machine learning in understanding the informational classification of image data form by using image classification , feature extraction , or other CV - based approaches . Alternatively , the parameterized US 11,295,552 B2 interface representation of base components may be used as inputs used in generating the classified interface represen- The classified interface representation , or in other words tation . In some variations the position of the device interface source is substantially static and configured in the extraction configuration . The selection of a sub - region of relevant image data can be directly performed based on the config an informational data representation , is a type of a param- 5 ured position of the device interface source . eterized interface representation data format that provides the symbolic meaning of the interface and is generally what an informed user would interpret from viewing the device . In the dial example used above , the classified interface representation would be the indicated value of the dial . An analyzed representation can be a higher order data information format resulting from applying high level logic , statistical analysis , and / or understanding of the information conveyed in the device interface source . The analyzed In other variations , block S131 may include detecting a device interface source and the position of the device interface source . This may be achieved through object recognition using CV - based approach . This could alterna tively be achieved through detection of a visual marker or a other suitable approaches . Block S132 , which includes formatting the image data , functions to prepare , normalize , and / or rectify the image data as part of the visual formatting stage . In some varia representation can be the result of applying high level logic 15 tions , the image data transformations prepare the image data and processing of the information as applied to the extracted interface presentation , and may use historical data , other data sources , and / or other resources in performing the analy- sis . for subsequent stages of processing or for a rendered inter face representation . The formatting the image data may additionally be used in generating a rendered interface representation that can be part of the extracted interface One or more of these extracted interface representations 20 representation output . may be exposed as shown in FIG . 26. In one preferred implementation , the extracted interface representation can expose a classified interface representation and the image- based rendered interface representation so that the ground Various visual transformations can be made including geometric transformations and imaging transformations . In one basic form of formatting the image data , the image data can be cropped to a region of interest for the device interface truth of the classified interface representation can be 25 source . For example , the image data may be converted to inspected . The extracted interface representation is preferably stored in association with a timestamp and can be periodically updated such that a longitudinal history of an extracted one or more sub - images that are cropped to some bounding box around the device interface source or some region of interest for the device interface source . The visual transfor mations are preferably specifically customized for regions of interface representation can be established . In some cases , 30 image data associated with different device interface sources however , a single or set of isolated snapshots of an extracted interface representation may be produced . As the extracted interface representation may not be collected with at regular intervals , data flagging or eventing may be triggered in such that each device interface sources can be normalized into an extracted interface representation . If there are two or more device interfaces sources captured by a camera , each device interface source can be transformed individually . response to issues in generating an extracted interface rep- 35 Image data transformations are preferably applied directly resentation . The processing of the image data may be scheduled such that it is executed at set intervals . The processing of the image data may alternatively be responsive to detection of on the image data , but can additionally include altering the configuration of an imaging device to transform image data though altering the image data collection process . Geometric transformations can rotate , skew , distort or the device interface source . A device interface source detec- 40 otherwise morph the geometry of one or more regions of the tion process can be executed continuously or periodically on the image data , and upon detection of the device interface source , the image data can be appropriately processed . This can be particularly applicable to variations using a movable image data of an interface to account for perspective . Accordingly , the viewing angle of a device interface source can accommodate rotation and non - normal viewing perspec tives . For example , screens viewed off angle are transformed imaging device , where the device interface source may not 45 to remove key - stoning in order to produce regular rectan always be present or located in the same region . The processing of the image data may alternatively be triggered through some input . For example , when integrated with a digital camera , the processing can execute after capture of gular images with aspect ratios that might match that of the screen of the original device . The amount of visual trans formation can additionally be used to characterize the qual ity of the collected data ( i.e. , the capture status ) . For the image data . In another example , a programmatic com- 50 example , a screen viewed from an extreme angle ( e.g. , mand may be communicated to an imaging device to capture image data and process the image data . Processing the image data can include a number of processing stages , which may involve a visual formatting eighty degrees off of a straight - on view ) may be less reliable . Reliability of the source of the extracted interface represen tation can be stored as a quality data property . The data property can depend on the base image data and / or other stage , recognition stage , classification and data formatting 55 aspects such as confidence in translating image data to a stage , and / or analysis stage . Accordingly , processing of the image data can include extracting image data associated with the device interface source S131 , formatting the image data S132 , extracting the interface output of the device parameterized value . Other visual transformations can include imaging trans formations , which functions to adjust the color space of the image data for enhanced legibility and / or processing . As interface source S133 , and / or analyzing the extracted inter- 60 with other image data transformations , imaging transforma face output S134 as shown in FIG . 27 . Block S131 , which includes extracting image data asso- ciated with the device interface source , functions to isolate the image data associated with the device interface source . tions can be customized to different regions of the image data . Imaging transformations can include adjusting the color space , brightness , contrast level , saturation level , hue , sharpness , white point , black point , and / or altering any Multiple cropped segments of image data can be created 65 suitable imaging variable . Filters or other image transfor from the image data if multiple device interface sources are mations may additionally be performed . The type of imaging transformations can be based on the type of extraction . present . US 11,295,552 B2 Block S133 , which includes extracting the interface out- put of the device interface source , functions to convert image data related to the device interface source into some form of a parameterized interface representation . A param- currently at a third location halfway between the minimum and maximum . This exemplary parameterized interface rep resentation can be converted to a classified interface repre sentation of fifty . The base parameterized interface repre eterized interface representation preferably includes a clas- 5 sentation may alternatively be used as input for machine observable dial setting . In some variations , extracting the 10 For example , a user may specify that the number characters sification and data formatting stage wherein a classified machine readable representation of an interpretation of the device interface source is produced . For example , the image of a dial can be converted to the interpreted meaning of the interface output may additionally include a recognition stage where components of the device interface source are detected . For example , a parameterized description of the position of the dial and the range of the dial in a generic In a recognition stage of extracting the interface output , visually represented information is preferably converted to a base parameterized interface representation . Accordingly , processing the image data may include extracting a param- description . learning analysis . The units assigned in the classification stage may be dynamically determined from the presented interface output but could alternatively be pre - configured during block S120 . read on a digital character display represent the temperature in Fahrenheit . Additionally formatting rules can be set to appropriately format the parameterized interface represen In one implementation for a type of extraction , computer vision classification may be applied in translating from image data to an extracted interface representation and more specifically a classified metric representation . As one poten tial solution for extracting an interface representation , the tation . eterized representation of the formatted image data . The 20 method may apply deep learning , neural nets , and / or other parameterized interface representation can be used in pro- viding a lower - level interpretation of the device interface source in between performing image processing and obtain- ing a classified interface representation . A base parameter- forms of machine learning models that are trained to trans late image data of a type of user interface to its interpreted meaning . The interpreted meaning can be normalized and then extraction configuration can be used in scaling that to ized interface representation is a parameterized data repre- 25 the intended interface output . For example , the positions of sentation of a visual description of the interface . In one variation , the parameterized interface format of a device interface source can be a data object with an array of graphical elements where each graphical element can have a radial and / or linear dial may be trained so that a normal ized position or angle of the dial can be detected through a neural network . Then the configured scale of the dial ( e.g. , linear / logarithmic , value range , etc. ) can be used to convert detected text , color properties , a location property , size 30 the normalized position or angle to a data value . Other properties , orientation properties and / or other properties . The properties of a data object for a base parameterized interface representation may depend on the type of extrac- tion . For example , a segmented character display can interfaces may be interpreted through deep learning where the visual appearance has a mapping to interpreted meaning . In the example above , the image of a dial may be classified as having a higher correlation to a set of images known to a include a first set of properties and a dial can have a second 35 have a particular symbolic mapping . a a a set of properties . Alpha / numerical characters are preferably recognized through optical character recognition ( OCR ) techniques or other processing techniques . A dial may be represented as an angular or linear position of the dial indicator as shown in FIG . 28 . In a classification and data formatting stage of extracting the interface output , the nature of the device interface source is interpreted into a classified interface representation also referred to as informational data . The classified interface The various types of configurable extraction modes may have specific processing steps customized to interpreting each type of interface . In a physical state detection mode , processing the image data associated with the device interface source into an extracted interface representation can include parameteriz ing visual physical state of the device interface source into an extracted interface representation . Parameterizing the visual physical state can include calculating size , tracking representation is a data format that provides the symbolic / 45 shape , tracking color profile , tracking orientation , tracking informational meaning of the interface and is generally what an informed user would interpret from viewing the device . A classified interface representation is preferably achieved through characterizing informational data from a base parameterized representation . A base parameterized interface format may be used to determine the symbolic meaning of the interface output . In one variation , a parameterized representation of the image data can then be characterized into a classified data repre- sentation , which provides more informational data that 55 reflects the conveyed information as opposed to a parametric description of the appearance of the interface . Alternatively , the image data may be used directly such as when using computer vision and machine intelligence to classify the position within a region , and / or tracking other attributes of the physical state of an object . In some instances , the device interface source is static , in which case the physical state can be processed when the device interface source is visible . In other instances , the device interface source may apply physical state detection upon detecting presence of a par ticular object . The physical state properties that are param eterized may be conditional based on the present object in a region of the device interface source . In an indicator detection mode , processing the image data associated with the device interface source into an extracted interface representation can include parameterizing the indi cator state of at least one indicator signal . One preferred type of indicator is lighted indicator signal in which case the meaning of the image data . The base parameterized interface 60 illumination state is parameterized , which may include format preferably represents the main components that define the mechanics of how the device interface source operates . The base parameterized interface representation can be logically analyzed to generate the classified interface parameterizing stable state of an indicator , parameterizing time varied states , parameterizing illumination qualities , and the like . This can include detecting an on and off state . There may additionally be other states . In one variation , the representation . For example , a dial may have a minimum 65 indicator state may be communicated through state varia value representing zero at a first location , a maximum value representing 100 at a second location , and an indicator tions over some window of time . For example , a certain number of flashes or rate of flashing can be detected and US 11,295,552 B2 mapped to a configured state . Color , brightness , and other illumination qualities of an indicator may also be detected and classified as different states . An indicator detection mode may additionally be used for physical indicators like switches , buttons , graphical indicators . In one variation , multiple indicators may as a collection indicate different information , and parameterizing can include parameterizing the collective state of the indicators . For example , three indicator lights may turn on and off in different combinations through logic in the extraction configuration . A switch extraction mode may be a type of indicator extraction . In a switch extraction mode , processing the image data associated with the device interface source into dimensions . A pie chart will have rules on angular interpre tation of wedges , and a line chart will have rules on interpretation of a line plotted along a two - dimensional axis . In the case of a medical monitoring device , a biological signal reflected as a line graph can be translated into a time ? series data - set . In a presence extraction mode , processing the image data associated with the device interface source into an extracted interface representation can include detecting at least one figuration . Detection of an object can include various forms of CV - based object detection . When dealing with people or more uniquely identifiable objects , presence extraction can to signal different information which could be interpreted 10 type of object in a region specified in the extraction con an extracted interface representation can include parameter- 15 be used for unique identification of objects . In the case of izing the mechanical state of a switch . The switch will preferably have at least two mechanically stable states , but could alternatively have multiple stable states . Multiple switches could additionally be monitored to determine some people , facial recognition , and / or other forms of biometric identification may be used . Presence detection mode may additionally include counting objects , measuring the quan tity , timing the duration of presence , or generating other logical state . With switches and indicators , the change in 20 metrics related to object presence . Multiple types of objects state at times may be of interest in addition to or as an alternative to just the stable state . In a dial extraction mode , processing the image data associated with the device interface source into an extracted interface representation can include parameterizing the set- 25 tings of a one - dimensional dial . This functions to measure the position of a dial indicator relative to the operating range along one dimension . In a rotary dial this may include measuring the angle of the dial indicator . In a linear dial this a may be detected . In some cases , presence extraction is used in detecting presence of some combination of objects in a region . Presence detection may additionally be accompanied by physical state detection . In a device model extraction mode , processing the image data associated with the device interface source into an extracted interface representation can include detecting device state of the device interface source , and processing the image data according to a detected device state . The may include measuring the position of the dial indicator 30 device model extraction mode functions to interpret device along a linear path . Accordingly , this may include detecting the dial indicator and measuring position and / or orientation relative to the dial range . Dials can include dials that are set into a position by user input as well as dials that are set in state of a device interface source . The device state is preferably detected according to a selected device model in the extraction configuration , wherein the selected device model extraction mode is on specifically extraction mode response to some signal . The dial extraction mode can 35 for the particular device model of the device interface additionally be applied to many situations that don't involve a traditional dial such as treating the level of contents in a container or bottle as a dial indicator that moves linear along the path defined along the container . A multi - dimensional source . For example , each brand and model of heart moni toring device may have a different customized device model extraction mode to accommodate the different forms of data , device states , and device state transitions Processing the dial or user input like a joystick with two - dimensions of 40 image data according to a detected device state can include extracted . positioning or another element could additionally be a In a character extraction mode , processing the image data associated with the device interface source into an extracted selecting a type of informational data for characterization based on the detected device state . Depending on the device state , different data ( or lack of data ) may be exposed through the interface . Processing the image data according to the interface representation can include performing optical char- 45 detected device state can additionally include extracting a acter recognition in a designated region . Related to character extraction , the method could addi- tionally include other forms of graphical interpretation that more generally includes parameterizing graphical state of parameterized representation of the device interface source from the image data and characterizing the parameterized representation into a labeled , informational data . The device state will generally change the type and form image data of the device interface source , which functions to 50 of information presented by the device interface source . interpret graphical presentation of information in an inter- face output . In a basic variation , this may be through identification and classification of static or animated graph- ics . Such graphic classification can enable graphical inter- Device state can be detected by interpreting device state from device indicators , tracking user interactions , and / or other approaches . Device indicators may include physical indicators like buttons , switches , LEDs , dials , and the like . pretation of non - alphanumeric symbols such as logos , icons , 55 Device indicators may additionally include graphically dis infographics , symbols , and / or other visual objects or pat- terns . Parameterizing graphical state , in one variation , may be used in parameterizing a chart ( e.g. , a line graph , pie chart , bar graph , or other form of infographic ) into a dataset . played indicators such as GUI menu labels . In one variation , the method can include generating a device state model based on display images labeled as different device states . In this way small graphical styles of different device states In the variation of interpreting a chart , interpreting the 60 ( e.g. , different applications , GUI widgets , and the like ) can graphical representation may include identifying a graphic type , detecting dimensions , identifying at least one data - set indicator , and generating at least one data - set value through comparison of a data - set indicator to the dimensions accord- be efficiently learned and represented as a model for clas sification . In a particular device state information is prefer ably presented in different ways . Each device state may have different information that can be extracted . Maintaining a ing to the graphic type . Graphic type can specify the rules for 65 state machine of device state may additionally be used to how data - sets and dimensions are represented and how a data - set indicator should be evaluated according to the associate information across different device states . For example , the method can interpret the navigation of a US 11,295,552 B2 a hierarchical menu in a modal operating system to understand classification of data extracted from a particular view . Block S134 , which includes analyzing the extracted inter- face output functions to perform post processing on the ing the extracted interface representation and providing API access . Exposing at least one access interface to the extracted interface representation could include exposing an API to a historical data record of the information data . In extracted interface representation . Depending on the appli- 5 another variation , the extracted interface representation cation , different forms of analysis may be applied . More generally , basic analysis post - processing processes can be configurable such as averaging over a window , converting a rate of change or acceleration of a metric , or other basic could be directly communicated to another system or appli cation . For example , a digital assistant , electronic product , or other form of device or product could be directly sent the extracted interface representation . In some variations , the processes . In some variations , the analysis may additionally 10 extracted interface representation can be converted to a include integrating with one or more other data sources , which may enable more in - depth analysis . The various types of extraction can additionally include other processing features to account for different operating control line so that the state of another connected system can be controlled in response to the extracted interface repre In another variation , exposing an interface can include sentation . attributes of a device interface source . Indicator interfaces 15 streaming a rendered interface representation . A user inter may also communicate information through a sequence of blinks . These sequences could be configured for detection , and block S130 could automatically detect these blinking conditions . Dial devices may offer the ability to move the face of the interface extraction system can be provided that organizes one or more device interface sources for remote monitoring . The rendered interface representation can addi tionally be streamed and / or accessed by multiple distinct dial continuously or more than a full rotation . Processing of 20 parties . In one variation , the rendered interface representa a a dial that is configured indicating such rotation range may be specifically tracked to account for being rotated beyond . Continuous tracking of the indicator may be used . Character tion includes at least part of the image data . The image data is preferably processed by at least a formatting stage . Intelligent streaming could include only transmitting based devices may operate with varying mechanics . A changes of the device interface source . In another variation , character - based display may scroll horizontally , scroll ver- 25 the rendered interface representation can be a virtual ren tically , or cycle through messages . Such display changes could be automatically tracked and accounted for in the processing stage to create better - structured data . Other device mechanics could additionally be accounted for . Additionally , during execution of the method , there may 30 be gaps in the monitoring a device interface source . The device interface source may be undetectable because the the lighting conditions change , the device interface source is temporarily moved , or other complica- view is blo dering of the interface that is driven by data extracted from the device interface source . The data could be in a param eterized interface representation , a classified interface rep resentation , or data from higher - level analysis . When applied in an industrial application where multiple device interface sources may benefit from grouped human monitoring , a rendered interface representation preferably enables the monitoring of a plurality of device interface sources . The various device interface sources may be orga tions . The method can preferably account for inconsistent 35 nized or categorized for group monitoring and / or analysis . data collection . The reason for a capture status change could be classified . Collected extracted interface representation data could be annotated indicating the capture status . Addi- tionally , configuration for extraction of device interface Additionally , the visual or data representation of one or more device interface sources can be presented in a structured format that organizes and prioritizes appropriate informa tion . In one exemplary use case , a rendered interface rep source could be set to send a notification or issue an alert 40 resentation can be streamed to a head nurse overseeing a during particular capture status conditions . Block S140 , which includes exposing at least one access interface to the extracted interface representation , functions to utilize the information obtained from the devices . The floor of patients in a hospital . The various device interface sources for each patient are grouped together . The head nurse can have an overview view where all patients can be monitored within one view . A patient view can enable the method could be applied in a variety of use cases , and the 45 nurse to select a particular patient for detailed monitoring type and manner of exposing an interface could be different depending on the use case . The exposed interface could be a user interface or a programmatic interface . The user interface could be accessed via a native application , a web the history of the device interface sources and / or lower priority information may be presented . In one implementation , the method may be used in combination with a programmatic event - handling system . application , or any suitable type of graphical , visual , or 50 The event - handling system may function to process the auditory user interface . Additionally , the user interface could be facilitated through a communication channel . Notifica- tions and alerts could be triggered based on different con- ditions of the extracted interface representations . For extracted interface representation and trigger a program matic event upon detecting an event . Various event condi tions could be monitored . The event conditions may be based in part on some aspect of the extracted interface example , an alert could be sent to one or more recipients in 55 representations . Then upon satisfying the condition a pro response to the classified interface representation satisfying some condition ( e.g. , heart rate dropping below a set value ) . A programmatic interface could be an application program- ming interface , a data communication protocol , a data grammatic event could be initiated . In another implementa tion , the interface to the extracted interface representation ( s ) could be integrated with a home automation hub wherein various IoT devices could be collectively managed . In storage solution , application processing routine , and / or any 60 another implementation , a user interface for remotely moni suitable mechanism enabling programmatic interactions . The programmatic interface can enable other applications and services to be integrated with the interface extraction system . toring the device interface source could be created . A wide variety of applications and tools could be constructed using The method may additionally include monitoring the the method . A programmatic interface to the extracted interface rep- 65 capture status of a device interface source and generating resentation ( s ) can be used to build various sets of tools and / or services . A programmatic interface may include stor- feedback in response to a change of capture status of the device interface source S150 , which functions to detect and US 11,295,552 B2 respond to problems of a device interface source being lost from view , blocked , angled to prevent accurate extraction , or otherwise obscured in the field of view of the imaging device . The feedback is preferably applied to address the changes so that actions can be taken to resolve issues . The capture status relates to the state of image data associated with device interface source that is used in processing . The capture status could be a binary status indicating if an extracted format can be generated . In another while the nurse is still helping the patient . When the nurse walks out of the room and is detected to leave the field of view of the image data , an audio announcement could play if the capture state of one or more device interface sources needs adjustments . The nurse will ideally hear and respond to the audio announcement and adjust the various device interface sources or make other adjustments to address the capture state issues . Feedback may alternatively be generated and associated variation , the capture status could be a reliability metric . 10 with data of the extracted interface representations . In cases Under ideal lighting conditions and a clear view of the device interface source the reliability metric can have a high rating . As the lighting conditions become less ideal and / or the angle of the device interface source moves off center , the where a device interface source is lost , the system can accommodate such gaps in information by flagging or annotating data . In some cases , the capture status could be a parameter associated with all extracted data formats . reliability metric may decline . At some level the capture 15 Similarly , the manner in which a device interface source was a status can indicate that a reliable extracted interface repre- a sentation is not obtainable . Audio interface elements could additionally have a cap- ture status . Capture status may be impacted by background noise , the volume settings of the device , the orientation of a 20 microphone of the interface extraction system , and / or other properties . Generating feedback in block S150 can be implemented in a variety of approaches . In one approach , the imaging lost could be classified and used to flag or annotate the data . Classifications for lost device interface sources can include obscured device , lighting conditions , off - angle view , and device interface source disappearance . To address possible changes in the capture status , the imaging device could be in close proximity to a device interface source to mitigate the chances of an object block ing view of the device interface source . In one variation , the imaging device can be mounted directly to the device device or another suitable device could generate user feed- 25 interface source such that the relative position and orienta back . The user feedback could be an audio alert such as a sound or announcement . The user feedback could addition- ally or alternatively be a visual alert such as activating a status light . The user feedback can communicate the issues fixed . tion of the imaging device and the device interface source is The method was primarily described as involving the use of a single camera of a single device interface source , but the with the capture status . For example , an audio announce- 30 method can be customized to work with multiple imaging ment may announce that the brightness settings of the display on a device need to be changed . In another example , a graphical display on an imaging device may indicate the “ signal strength ” based on the image data conditions . devices and / or with multiple device interface sources . In one variation , multiple imaging devices may be used to collect extracted interface representations of a device inter face source . These different imaging devices may be used at a In one preferred implementation , generating feedback can 35 distinct times or overlapping times . In one exemplary sce include announcing a change in capture status during user exit of the field of view . In this implementation , the method may additionally include tracking user presence in the field of view of the image data , which can enable detecting the nario , image data is captured by at least a first imaging device and a second imaging device ; and processing the image data associated with the device interface source into an extracted interface representation can include processing user exit . In some cases , humans may commonly enter the 40 image data collected from the first imaging device at a first field of view obscuring or altering the capture status of a device interface . While a human that causes the change is present in the field of view , the method can assume that the human is interacting with the device interface sources and instance into an extracted interface representation of the device interface source during the first instance and process ing image data collected from the second imaging device at a second instance into an extracted interface representation performing the task of monitoring information from the 45 of the device interface source during the second instance . device interface source . In other words , the method can temporarily delegate device interface source monitoring to a user when the user is in the vicinity of the device interface source . This can be particularly useful in a hospital use case The method is preferably operable for use with multiple device interface sources , wherein the method may include setting two or more device interface sources , and for each instance of extraction configuration of a device interface where nurses and doctors will enter a patient's room , view 50 source , processing the image data associated with the the device interface sources , and interact with the device interface sources . The method may additionally be able to distinguish between different users . For example , the method can be configured to distinguish between hospital respective device interface sources into extracted interface representations according to the respective extraction con figuration . The extracted interface representations of the different device interface sources are preferably managed as workers and other people ( e.g. , patients , patient family 55 separate and distinct data feeds ( unless configured for merg members , etc. ) . The appropriate users can be tracked through the image data ( or other sources of location infor- mation like GPS or RF - based triangulation ) , and when the user leaves the proximity of the device interface source , the ing ) . The exposed access interface may be used to access the extracted interface representations of select device interface sources or multiple device interface sources . In one variation of the method , the image data is collected user can be alerted to any issues with the monitoring 60 by a movable imaging device . A movable imaging device conditions . As an exemplary scenario shown in FIG . 29 , a nurse walks into a patient's room . While the nurse is checking on the patient , they may move a monitor device and / or block . may be a camera on a smart phone , a tablet computer , a wearable computer such as smart glasses or a body camera , an imaging system of a robot , automobile , or movable machine , or any suitable device that is generally not stati the view of the monitor device . During this time the capture 65 cally positioned . status will indicate that data cannot be collected from the device interface source , but user feedback is not generated The movable cameras will preferably be exposed to many more potential device interface sources . And the method US 11,295,552 B2 may employ automatic enrollment and configuration of device interface sources to facilitate accommodating the volume of device interface sources to be extracted . In one variation , the device interface sources may be automatically image data in response to the device position corresponding to a possible device interface source . In a glasses variation , eye tracking may additionally be used in identifying the object or region of image data viewed configured on demand in response to some condition . In 5 by a user . This may be used in directing the processing of another variation , the method can include enabling proactive processing of detected device interface sources that are pre - configured with extraction configuration . image data to generate an extracted interface representation . This may additionally be used in selecting an object for extraction configuration . In a movable imaging device variation , the method may include collecting image data Silo ; setting extraction con 10 device and user , but a shared platform may additionally The device interface sources may be associated with the figuration of a device interface source identified in the image data , where the extraction configuration includes setting a device position S120 ; tracking an image collection position S160 ; processing the image data associated with the device interface source into an extracted interface representation according to the extraction configuration and responsive to when the image collection position corresponds to a con figured device position of the device interface source S135 ; data . collect device interface sources so that the network of imaging devices can cooperate in sharing extraction con figuration and collection image data and processing image The method may additionally include detecting a candi date device interface source . In one variation , such auto matic enrollment and configuration can be performed inde pendent of any configured device position to enable on - demand extraction of data from a device interface source . a and exposing at least one access interface to the extracted 20 The method actively captures image data and processes the interface representation S140 as shown in FIG . 30 . Block S160 , which includes tracking image collection position , functions to detect position and / or orientation within an environment or global setting . In one variation , image data for device interface source detection upon detec tion . Interface source detection can use CV - based object classification and detection techniques . When a device inter face source is detected , it can be processed according to an tracking image collection position includes collecting global 25 extraction configuration based the type of device interface positioning coordinates and / or device orientation measure- ments of the movable imaging device as shown in FIG . 31 . In one implementation , the imaging device is integrated into a computing device with a location service that can leverage source . Without configuring a device position the extracted interface representation may not be part of a larger historical record of the device interface source and instead provide a snapshot for the duration that device interface source was GPS and / or cellular / Wi - Fi location detection . The comput- 30 viewable . Alternatively , detection of a candidate device ing device may additionally include an inertial measurement unit ( IMU ) , which may include an accelerometer , a gyro- scope , and a magnetometer . The IMU may be used detect the orientation of the imaging device and direction of the interface source can be used along with setting device position such that a historical record of that device interface source can be generated . Accordingly , the method shown in FIG . 30 can include detecting at least one type of device a imaging device . The image collection position may addi- 35 interface and automatically setting extraction configuration tionally include determining a spatial estimation of an environment from collected image data . A spatial estimation can use various spatial sensing technology integrated into the computing device , processing multiple images , and / or of a device interface upon detection of a type of device interface , wherein the extracting configuration sets device position to map to the image collection position . The movable camera variation of the method may include using other techniques used in generating a spatial map . The 40 the scenario where multiple imaging devices that are oper spatial map may additionally be used in understanding what is viewable by the movable device at different moments . Additionally or alternatively , tracking image collection position can include tracking visual mapping of a scene , ated by different users can collect extracted interface repre sentations of a device interface source at different times . The method may enable sharing of extracted interface represen tations so that the collaborative collection of imaging data which functions to use image mapping within a localized 45 and processing can provide more data points of a device area . The image data can be compared to past image data of a device interface source . The visual mapping will signal when similar scenes are detected which can increase the likelihood that the device interface source can be detected . interface source . Sharing can function to share data across accounts and devices . Sharing can be particularly useful for a movable camera , as image data of a device interface source will likely only be periodically processed . Sharing of data Visual mapping may be activated when GPS indicates 50 and processing may expand the number of opportunities to approximate proximity to a device interface source . In one variation , tracking of image collection position can be used in setting the device position during setting of the extraction configuration . During setting of the extraction observe and process a device interface source . For example , a family with sharing of extraction configuration for device interfaces at their home may be able to provide more data on monitored devices . An interface extraction platform in com configuration , positioning of the movable imaging device is 55 munication with the different imaging devices can prefer preferably used to establish an estimation of the location of a device interface source . GPS and location information can provide rough location . Orientation may provide informa- tion such as if the device interface source is located high or ably coordinate the sharing of image data and / or extracted interface representations . There may be cases though where one would desire to restrict capabilities to perform interface extraction . The low . Spatial estimation can be used to understand from 60 movable camera variation ( along with other variations ) may where the device interface source may be viewable . Tracking of image collection position is additionally used in determining when image data should be processed . The method can search for device interface sources that may be enable permissions to augment the sharing of image data and / or extracted interface representations . A policy engine can preferably enable , disable , or regulate processing of image data into extracted interface representations and the viewable based on the tracked image collection position . It 65 accessing of generated extracted interface representations of can similarly applied to selectively activate a collection of image data . For example , a device may initiate collection of different devices based on the privileges associated with that account . The interface extraction platform in communica US 11,295,552 B2 tion with the devices may be able to remotely enforce the policy engine . Alternatively , the policy engine may have access to a local copy of permissions that can be enforced on - device . regional permissions of extraction configuration to a first account for a first region ; wherein setting of the extraction configuration of a device interface source is restricted to configuration by the first account . The first account or set of a In one variation , imaging devices can be associated with 5 accounts in this example , is the only one enabled to set user accounts such that registering of an imaging device can set how permissions are enforced for that imaging device . The user accounts may additionally be used in accessing data or services using the extracted interface representations . a extraction configuration for a device interface source in that first region . Alternative instances may allow some limited options of setting extraction configuration . For example , a second user that brings an object already associated with Any suitable identity mechanism may be used in place of 10 extraction configuration into the first region may still be user accounts . In one instance , a movable camera may be associated with a first account and used in collecting image data that is processed into an extracted interface represen- tation . However , exposing an access interface to the data permitted to manage permissions for that object . 4. System As shown in FIG . 32 , a system for establishing remote integration with a device through a user interface output of may permit a second account to access the extracted inter- 15 a preferred embodiment can include an imaging system 110 , face representation and prohibit and / or restrict the first account from reading , accessing , or otherwise using the extracted interface representation . The permissions can permit , restrict , or otherwise limit a device interface processing engine 120 , and an access interface 1300. The interface extraction system is preferably used for extracting user interface outputs of a device that would be available to a user for interpretation and convert the processing of image data into extracted interface repre- 20 ing the related information to an extracted interface repre sentations and / or accessing collected extracted interface representations . Permissions for processing can be used to prevent conversion of image data into an extracted interface representation . Permissions for accessing may be used to sentation for remote access and integration . The device interface source preferably includes a visual interface but may additionally or alternatively have audio - based interface elements . The user interface of a device can be an explicit allow the collection of image data for processing but then 25 user interface like a display but may alternatively be an prevent access from particular entities possibly including the user that assisted in collecting and / or processing the image data . In one instance , the permissions can be used to grant one particular type of account permission to facilitate the generation of extracted interface representation data but to 30 prevent access to the data the account generated . In an example of this instance , a first user account is associated with an imaging device and is permitted to access extracted interface representation data for a particular device interface analog user interface like the fluid level in a container ( e.g. , an I.V. bag level ) , a knob position , or dial position . The system preferably implements the method described above but may alternatively be used in any suitable manner . The system can be implemented to monitor a single region . The system may alternatively be implemented to monitor a plurality of distinct regions . For example , a hospital may have multiple imaging systems 110 installed in multiple patient rooms , and the system can facilitate indi source . In this example , a second user account is associated 35 vidually monitoring the various device interface sources in with a second imaging device may also assist in the gen- eration of extracted interface representation data , but the second user account may be prohibited from accessing the extracted interface representation of the device interface source through an exposed interface . Permissions can be conditional on associated account , device position , device interface source identity ( e.g. , a particular device interface source ) , device interface source type ( e.g. , a particular type of device source such as a the multiple patient rooms . In one embodiment , the system is implemented within a remote interface extraction platform . The interface extrac tion platform can integrate with the imaging system 110 , include at least a portion of the device interface processing engine 120 , and provide one or more access interfaces 130 . In one variation , the remote interface extraction platform is a multi - tenant platform wherein multiple different accounts can run distinct instances of the system through the platform . particular type of computing device ) , time of day , number of 45 Alternatively , a single - tenant solution could be used in place data points , and / or other factors . Permissions can be set for specific user accounts or based on properties of user accounts such as group association ( e.g. , part of a family , friend , or work group ) , residency , and the like . Position and of a remote interface extraction platform . For example , a server application could act as an on - premise platform . In yet other implementations , a stand - alone imaging device may be designed to include the imaging system 110 , device geographic region may be used in many cases for condi- 50 interface processing engine 120 , and the capture device state Permissions may be set by administrators of the system . Permissions may alternatively be set by individual users . In one implementation , the method can include granting per- The imaging system 110 functions to collect media and more preferably the image data that may contain a device interface source . The imaging system 110 can include one or mission administrator rights to a restricted geographic area 55 more imaging devices . The image data collected by the to a user account . Accounts could alternatively be granted permission administrator rights over particular device inter- face source types ( e.g. , manufacturers of a particular device ) . Claiming of permission administrator rights pref- imaging system is preferably video but can alternatively be a set of periodic static images . The imaging devices are preferably visual video or still cameras , but may additionally or alternatively collect infrared , depth - based , lidar , radar , erably includes validating the request to ensure the account 60 sonar , and / or other types of imagery . The imaging system should be granted those rights . For example , granting per- mission administrator rights to a restricted geographic area may depend on proof of residency and / or ownership of that geographic area . In this way , homeowners and / or business can additionally include a low - light / night mode . For example , an IR illumination system could emit IR light and collect image data from the IR spectrum during low light or nighttime mode . Depth imaging devices , and other suitable owners can restrict and control interface extraction with 65 forms of imaging devices may additionally or alternatively and / or at their property . In one instance of granting permis- sion administrator rights , the method may include setting be used . An imaging device is preferably mounted such that a region of interest is in the field of view of the imaging tional permissions . interface . US 11,295,552 B2 device . The imaging device can be static such that the field of view is substantially not dynamic . Alternatively , the imaging device could be actuated where the field of view can be changed by rotating , elevating , panning , zooming , mov- ing and / or otherwise altering the field of view . In one variation , the imaging system 110 could include a free moving imaging device ( i.e. , a movable imaging device ) such as one worn by a user . An imaging device is preferably a standalone imaging device with a power source and a alternative embodiment the system can be implemented with only visual , only microphones , or only chemical sensors , or any combination where interface cues can be collected and processed without other forms data collection . The device interface processing engine 120 functions to process the image data from the imaging system to extract the state of a device interface source . The device interface processing engine 120 is preferably configured in coopera tion with the imaging system 110 to execute the processing network interface ( e.g. , wired or wireless ) . Processing may 10 of image data into an extracted interface representation be performed on the imaging device but may alternatively be performed entirely or in part on a remote device . In one variation , the imaging system 110 could be a vision system interface that enables integration with an existing imaging a system 110 ( e.g. , surveillance cameras ) . a In a variation with a movable imaging device , the imaging device can additionally include or have access to positioning and / or orientation sensing devices such as a location service of a computable device ( e.g. , using GPS and / or cellular / Wi- described above . In one implementation , the device interface processing engine 120 can include a pre - processing model and / or an analysis engine . The device interface processing engine 120 preferably operates on image data associated with a device interface source . The region of image data associated with a device interface source could be pre configured but may alternatively be automatically detected . The pre - processing module functions to transform image data that relates to a device interface source . A cropped copy Fi location ) and / or an IMU ( e.g. , including a three - axis 20 of image data can be generated for each device interface accelerometer , a three - axis gyroscope , and a magnetometer ) . In a variation with an imaging system network , the imaging system 110 can include a multitude of imaging devices distributed in the environment with the imaging source . Various visual transformations including geometric transformations and imaging transformations can be applied to the image data within the pre - processing module . The analysis engine functions to synthesize image data devices positioned at a range of distinct vantage points . 25 associated with a device interface source into an interpreted When installed for enabling interface extraction across an environment , the imaging system 110 may be a high - density imaging system . A high - density imaging system is prefer- ably characterized by a large portion of the relevant portions representation . There could be multiple stages and processes executed by the analysis engine . The analysis engine pref erably operates on the output of the pre - processing module . The analysis engine could facilitate processing a classifica of environment normally observed by an image capture 30 tion stage , an integration stage , and / or one or more higher device . A large portion , in one example , can be characterized as greater than 95 % of surface area of interest . High density may additionally be characterized as having redundant cov- erage . In one example , high density imaging system may be level analysis stages . In a classification stage , optical char acter recognition can be applied on the image data . Image ! symbol classifi on , color dete matching , and / or other forms of classification can be used to audio pattern characterized by one camera for every one hundred square 35 generate a parameterized interface representation . A second feet of surface area of interest ( e.g. , the ground , product storage faces , etc. ) . In an environment like a small grocery store this can may be twenty or more cameras distributed for coverage of two thousand square feet of surface area of ary classification stage can operate directly on the param eterized interface representation to interpret the presented information . Additionally , the device state interpreter can be used to interpret the presented information . An integration interest . The imaging device to environment space ratio 40 stage functions to combine multiple pieces of information . could be any suitable ratio . The system could alternatively use a sparse network of imaging devices with little or no overlap of fields of view . The imaging system 110 preferably continuously or peri- The different pieces of information can be retrieved from one or more device interface sources . Various higher - level analysis systems can perform real - time or historical analysis of the generated information . For example , higher - level odically collects image data that is processed by the device 45 analysis could analyze all the different meters and initiate an interface processing engine 120. The imaging system 110 may alternatively be dynamically controlled to collect image data on demand to collect image data for the device interface processing engine . The capture configuration of an imaging alert . The access interface 130 functions to offer some form of access to the collected extracted interface representations . The access interface 130 could be a user interface such as a device could be statically set but may alternatively be 50 dashboard for accessing and exploring collected data . The dynamic . Capture configuration can include any suitable imaging setting such as ISO , aperture , shutter speed , zoom , or other settings . The capture configuration could be dynamically altered based on one or more results of the access interface 130 could alternatively be a media commu nication interface such as a formatted video stream or notification / alert system . The access interface 130 could alternatively be a programmatic interface such as an appli a device interface processing engine 120. The capture con- 55 cation programming interface ( API ) or an application pro figuration could additionally operate in alternating capture configurations so as to cycle through camera settings cus- tomized for different device interface sources . Herein , the system is primarily described as it would be cessing engine . An API can enable outside applications or services to remotely interact with the collected data . An application processing engine could enable scripts or appli cations to be processed and executed at least in part by the used for visual interface extraction . The system could addi- 60 system . For example , higher - level analysis processes may be tionally or alternatively utilize one or more microphones to collect audio , vibration , and ultrasonic signals and convert the collected data into an extracted sound - pressure interface representation of the device . The system could additionally designed and configured by a third party . The system could additionally include a control interface , which functions to enable configuration of the imaging system and / or the device interface processing engine 120 . or alternatively utilize one or more chemical sensors to 65 The control interface is preferably a user application oper collect signals and convert the collected data into extracted chemical interface representations of the device . In an able on a computing device such as a smart phone , a personal computer , a wearable computer , and / or any suitable US 11,295,552 B2 computing device . When setting up the system for a device interface source , the user can use the control interface to set various configuration options . The user could specify the position of the device interface source within the image data , the type of extraction , set some of the operating properties . In one variation , live image data can be streamed from the imaging system 110 to the control interface so that configu ration can be performed and previewed on the current state of the device interface source . Additionally , the control interface may be one user interface for viewing and moni- 10 toring extracted interface representations of the device inter face source . The system may additionally include an interface extrac tion platform that is a network accessible platform or service a setting extraction configuration of a device interface source identifiable in the image data and associated with a device position ; tracking image collection position of the movable imag ing device ; when the image collection position corresponds to the device position of the device interface source , process ing the image data associated with the device interface source into an extracted interface representation according to the extraction configuration ; and exposing at least one interface to the extracted interface representation . 2. The method of claim 1 , wherein setting the extraction that can be used to facilitate in the processing and / or 15 configuration of the device interface source comprises selecting at least one of a set of extraction modes for the at management of data . The interface extraction platform in one implementation can host the device interface processing engine 120 in part or full . A control interface like a user application may have least one device interface source . 3. The method claim 2 , wherein the set of extraction modes comprises a physical state detection mode , an indi communication access to the interface extraction platform so 20 cator detection mode , a dial extraction mode , an alphanu meric character extraction mode , and a presence extraction that processing tasks and / or data can be synchronized between different device instances . APIs , web dashboards , administrator control panels , and / or other forms of access interfaces may be provided through the interface extraction mode . platform . In one variation , extraction configuration and data 25 tion configuration , and wherein processing the image data on the various device interfaces can be stored and managed by the interface extraction platform . The system may additionally include a policy engine that functions to manage sharing of data and interface extraction capabilities . The permissions that can be set by the policy 30 engine are preferably substantially similar to the ones described above . The policy engine can be integrated into the interface extraction platform but may alternatively oper ate locally with the device interface processing engine 120 . embodied and / or implemented at least in part as a machine configured to receive a computer - readable medium storing computer - readable instructions . The instructions can be executed by computer - executable components integrated 4. The method of claim 2 , wherein the extraction con figuration of the device interface source is a gesture detec associated with the device interface source comprises detect ing at least one type of gesture event in a region specified in the extraction configuration when set in the gesture detection mode . 5. The method of claim 2 , wherein the extraction con figuration of the device interface source is a device model extraction configuration , and wherein processing the image data associated with the device interface source comprises ing to a selected device model extraction mode and , in accordance with the device state , extracting a parameterized representation of the device interface source from the image data and characterizing the parameterized representation The systems and methods of the embodiments can be 35 detecting device state of the device interface source accord with the application , applet , host , server , network , website , 40 into a labeled data . communication service , communication interface , hard- ware / firmware / software elements of a user computer or mobile device , wristband , smartphone , or any suitable com- bination thereof . Other systems and methods of the embodi- 6. The method of claim 1 , wherein the extraction con figuration of the device interface source is a physical state detection configuration , and wherein processing the image data associated with the device interface source comprises ment can be embodied and / or implemented at least in part as 45 parameterizing the physical state of the device interface a machine configured to receive a computer - readable medium storing computer - readable instructions . The instructions can be executed by computer - executable com- ponents integrated by computer - executable components source into an extracted interface representation when con figured in the physical state detection mode . 7. The method of claim 6 , wherein the physical state detection mode is a dial extraction mode , wherein param integrated with apparatuses and networks of the type 50 eterizing visual physical state of the device interface source described above . The computer - readable medium can be stored on any suitable computer readable media such as RAMS , ROMs , flash memory , EEPROMs , optical devices ( CD , DVD , etc. ) , hard drives , SSHDs , or any suitable into an extracted interface representation comprises param eterizing the settings of a one - dimensional dial . 8. The method of claim 6 , wherein the physical state detection mode is a switch extraction mode , wherein param device . The computer - executable component can be a pro- 55 eterizing visual physical state of the device interface source cessor , but any suitable hardware device can ( alternatively or additionally ) execute the instructions . As a person skilled in the art will recognize from the previous detailed description and from the figures and into an extracted interface representation comprises param eterizing the mechanical state of a switch with at least two mechanically stable states . 9. The method of claim 6 , wherein the physical state claims , modifications and changes can be made to the 60 detection mode is an indicator detection mode , wherein embodiments of the invention without departing from the scope of this invention as defined in the following claims . We claim : parameterizing visual physical state of the device interface source into an extracted interface representation comprises parameterizing the illumination state of an indicator signal with at least two illumination states . 1. A method for establishing uncoupled information 65 extraction from a user interface output comprising : collecting image data from a movable imaging device ; 10. The method of claim 1 , wherein the extraction con figuration of the device interface source is a character extraction configuration , and wherein processing the image US 11,295,552 B2 figuration of the device interface source is a presence 5 interface representation and prohibits the first account from data associated with the device interface source comprises recognizing visible characters and converting the visible characters into a data format . 11. The method of claim 1 , wherein the extraction con detection configuration , and wherein processing the image data associated with the device interface source comprises detecting at least one type of object in a region specified in the extraction configuration when set in the presence detec tion mode . 12. The method of claim 1 , further comprising detecting a type of device interface source in the image data through object recognition , and automatically setting the extraction configuration the detected device interface source according to the type of device interface source . 13. The method of claim 1 , wherein setting extraction 15 configuration of at least one device interface source com prises receiving manual configuration input through a coupled management application . 14. The method of claim 1 , further comprising providing a visual marker and wherein setting the extraction configu- 20 ration of the device interface source comprises detecting the visual marker in the image data and setting at least part of the extraction configuration based on properties of the visual marker . 15. The method of claim 1 , wherein the image data is 25 captured by at least a first mobile imaging device and a second mobile imaging device ; and wherein processing the image data associated with the device interface source into an extracted interface representation further comprises pro cessing image data collected from the first mobile imaging 30 device at a first instance into an extracted interface repre sentation of the device interface source during the first instance and processing image data collected from the second mobile imaging device at a second instance into an extracted interface representation of the device interface 35 source during the second instance . 16. The method of claim 1 , wherein tracking image collection position comprises collecting positioning coordi nates and a device orientation measurement of the movable a 17. The method of claim 1 , wherein tracking image collection position further comprises tracking visual map imaging device . ping of a scene . 18. The method of claim 1 , wherein the movable imaging device is associated with a first account , and wherein expos ing at least one interface to the extracted interface represen tation permits a second account to access the extracted reading the extracted interface representation . 19. A non - transitory computer - readable medium storing instructions that , when executed by one or more computer processors of a computing platform , cause the computing platform to : collecting image data from a movable imaging device ; setting extraction configuration of a device interface source identifiable in the image data and associated with a device position ; tracking image collection position of the movable imag ing device ; when the image collection position corresponds to the device position of the device interface source , process ing the image data associated with the device interface source into an extracted interface representation according to the extraction configuration ; and exposing at least one interface to the extracted interface representation . 20. A system comprising of : one or more computer - readable mediums storing instruc tions that , when executed by the one or more computer processors , cause a computing platform to perform operations comprising : collecting image data from a movable imaging device ; setting extraction configuration of a device interface source identifiable in the image data and associated a with a device position ; a tracking image collection position of the movable imaging device ; when the image collection position corresponds to the device position of the device interface source , pro cessing the image data associated with the device interface source into an extracted interface represen tation according to the extraction configuration , and exposing at least one interface to the extracted interface representation . * *