{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce14dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/sully/RAGPROJ/embeddings/embeddings.npy'),\n",
       " WindowsPath('C:/Users/sully/RAGPROJ/embeddings/chunk_metadata.jsonl'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from openai import OpenAI  # OpenAI Python SDK\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "EMB_DIR = PROJECT_ROOT / \"embeddings\"\n",
    "\n",
    "EMB_PATH = EMB_DIR / \"embeddings.npy\"\n",
    "META_PATH = EMB_DIR / \"chunk_metadata.jsonl\"\n",
    "\n",
    "EMB_PATH, META_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00239d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings: (2905, 384)\n",
      "Loaded metadata records: 2905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'US10452978_0',\n",
       "  'patent_id': 'US10452978',\n",
       "  'chunk_index': 0,\n",
       "  'text': 'US010452978B2 ( 12 ) United States Patent Shazeer et al . ( 10 ) Patent No . : US 10 , 452 , 978 B2 ( 45 ) Date of Patent : Oct . 22 , 2019 ( 54 ) ATTENTION - BASED SEQUENCE TRANSDUCTION NEURAL NETWORKS ) U . S . Ci . ( 71 ) Applicant : Google LLC , Mountain View , CA ( US ) ( 58 ) Field of Classification Search CPC . . . . . . . . . . . . . . . . . GOON 3 / 08 ( 2013 . 01 ) ; G06N 3 / 04 ( 2013 . 01 ) ; G06N 3 / 0454 ( 2013 . 01 ) CPC USPC . . . . . . . . . . . . . . . . . . . . . . . . . GOOF 3 / 015 . . . . . . 706 / 15 , 45 See application file for complete search history . ( 72 ) Inventors : Noam M . Shazeer , Palo Alto , CA ( US ) ; Aidan Nicholas Gomez , Toronto ( CA ) ; Lukasz Mieczyslaw Kaiser , Mountain View , CA ( US ) ; Jakob D . Uszkoreit , Portola Valley , CA ( US ) ; Llion Owen Jones , San Francisco , CA ( US ) ; Niki J . Parmar , Sunnyvale , CA ( US ) ; Illia Polosukhin , Mountain View , CA ( US ) ; Ashish Teku Vaswani , San Francisco , CA ( US ) ( 73 ) Assignee : Google LLC , Mountain View , CA ( US ) ( * ) Notice : Subject to any disclaimer , the term of this'},\n",
       " {'id': 'US10452978_1',\n",
       "  'patent_id': 'US10452978',\n",
       "  'chunk_index': 1,\n",
       "  'text': 'Polosukhin , Mountain View , CA ( US ) ; Ashish Teku Vaswani , San Francisco , CA ( US ) ( 73 ) Assignee : Google LLC , Mountain View , CA ( US ) ( * ) Notice : Subject to any disclaimer , the term of this patent is extended or adjusted under 35 U . S . C . 154 ( b ) by 0 days . ( 21 ) Appl . No . : 16 / 021 , 971 ( 22 ) Filed : Jun . 28 , 2018 ( 65 ) Prior Publication Data US 2018 / 0341860 A1 Nov . 29 , 2018 Related U . S . Application Data ( 63 ) Continuation of application PCT / US2018 / 034224 , filed on May 23 , 2018 . No . ( 60 ) Provisional application No . 62 / 541 , 594 , filed on Aug . , 2017 , provisional application No . 62 / 510 , 256 , filed on May 23 , 2017 . ( 51 ) Int . Cl . G06F 15 / 18 GO6N 3 / 08 GOON 3 / 04 ( 2006 . 01 ) ( 2006 . 01 ) ( 2006 . 01 ) ( 56 ) References Cited PUBLICATIONS Luong et al . , Effective Approaches to Attention - based Neural Machine Translation , ( 2015 ) Conf . on Empirical Methods in Natural Lan guage Processing at p . 1412 - 1421 ( Year : 2015 ) . * ( Continued ) Primary Examiner - David R Vincent ( 74 ) Attorney , Agent , or Firm — Fish & Richardson P . C . ( 57 ) ABSTRACT Methods , systems , and apparatus , including computer pro grams encoded on a'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_embeddings_and_metadata(emb_path: Path, meta_path: Path):\n",
    "    embeddings = np.load(emb_path)\n",
    "    chunks = []\n",
    "    with meta_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            chunks.append(json.loads(line))\n",
    "    print(f\"Loaded embeddings: {embeddings.shape}\")\n",
    "    print(f\"Loaded metadata records: {len(chunks)}\")\n",
    "    return embeddings, chunks\n",
    "\n",
    "embeddings, chunks = load_embeddings_and_metadata(EMB_PATH, META_PATH)\n",
    "chunks[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6654e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn_index(embeddings: np.ndarray, n_neighbors: int = 5):\n",
    "    nn = NearestNeighbors(\n",
    "        n_neighbors=n_neighbors,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "    nn.fit(embeddings)\n",
    "    return nn\n",
    "\n",
    "nn_index = build_nn_index(embeddings, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de215854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_chunks(\n",
    "    query: str,\n",
    "    embed_model,          # SentenceTransformer model from 03, or reload it\n",
    "    nn_index,\n",
    "    embeddings,\n",
    "    chunks,\n",
    "    top_k: int = 5,\n",
    "):\n",
    "    # embed query\n",
    "    q_emb = embed_model.encode([query])\n",
    "    \n",
    "    # retrieve\n",
    "    distances, indices = nn_index.kneighbors(q_emb, n_neighbors=top_k)\n",
    "    \n",
    "    results = []\n",
    "    for rank, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "        rec = chunks[idx]\n",
    "        results.append({\n",
    "            \"rank\": rank,\n",
    "            \"score\": 1 - float(dist),  # cosine similarity approx\n",
    "            \"id\": rec[\"id\"],\n",
    "            \"patent_id\": rec[\"patent_id\"],\n",
    "            \"chunk_index\": rec[\"chunk_index\"],\n",
    "            \"text\": rec[\"text\"],\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9615875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sully\\RAGPROJ\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "embed_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f169ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] US12148421 (sim=0.580)\n",
      "part of a dialog session between a user of a client device and an automated assistant implemented by the client device: receiving a stream of audio data that captures a spoken utterance ofthe user, the stream of audio data being generated by one or more microphones of the client device, and the spok ...\n",
      "\n",
      "[1] US11562147 (sim=0.577)\n",
      "an utterance of the human user in the dialogue history or a language model response. 14. The system of claim 11, wherein a position level encoding layer from the plurality of text encoding layers generates the position level encoding, wherein the position level encoding identifies a token ordering i ...\n",
      "\n",
      "[2] US11562147 (sim=0.575)\n",
      "visual dialogue model 55 receives the image 110, the dialogue history 120 and the question 130 as input and generates the answer 150 base on the received input. Prior approaches have attempted to implement visual dialogue, where a dialogue machine agent is tasked to answer a series of questions grou ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"How does this invention handle language model dialogue?\"\n",
    "hits = search_chunks(test_query, embed_model, nn_index, embeddings, chunks, top_k=3)\n",
    "\n",
    "for h in hits:\n",
    "    print(f\"[{h['rank']}] {h['patent_id']} (sim={h['score']:.3f})\")\n",
    "    print(h[\"text\"][:300], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0aed2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e31f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()  # uses OPENAI_API_KEY env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cecb472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_string(retrieved_chunks):\n",
    "    pieces = []\n",
    "    for r in retrieved_chunks:\n",
    "        header = f\"[{r['patent_id']} | chunk {r['chunk_index']} | score={r['score']:.3f}]\"\n",
    "        pieces.append(header + \"\\n\" + r[\"text\"])\n",
    "    return \"\\n\\n---\\n\\n\".join(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dea67f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(\n",
    "    question: str,\n",
    "    embed_model,\n",
    "    nn_index,\n",
    "    embeddings,\n",
    "    chunks,\n",
    "    client,\n",
    "    model: str = \"gpt-4.1-mini\",\n",
    "    top_k: int = 5,\n",
    "):\n",
    "    # 1. Retrieve\n",
    "    retrieved = search_chunks(\n",
    "        question,\n",
    "        embed_model,\n",
    "        nn_index,\n",
    "        embeddings,\n",
    "        chunks,\n",
    "        top_k=top_k,\n",
    "    )\n",
    "    context = build_context_string(retrieved)\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant answering questions about a small set of US patents. \"\n",
    "        \"Answer the user's question using ONLY the information in the provided context. \"\n",
    "        \"If the answer is not in the context, say you don't know based on these documents.\"\n",
    "    )\n",
    "    \n",
    "    user_prompt = (\n",
    "        f\"Question:\\n{question}\\n\\n\"\n",
    "        f\"Context (patent chunks):\\n{context}\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    return answer, retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa611ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "What is the main novelty of these inventions related to language model training or dialogue systems?\n",
      "\n",
      "ANSWER:\n",
      "The main novelties of the inventions related to language model training or dialogue systems, as described in the provided patents, include:\n",
      "\n",
      "1. **Dataset Generation Using Large Language Models (US20240185001A1)**: This invention introduces a system and technique for generating training datasets for task-oriented dialogue systems by leveraging large language models (LLMs). The method involves selecting template queries, sampling domain-specific tokens, modifying the templates with these tokens to create query prompts, and then using an LLM to generate diverse natural language queries. These generated queries are then used to train conversational machine-learning models tailored to specific domains. This approach automates and enhances the creation of relevant training data, which is crucial for effective domain-specific dialogue system training.\n",
      "\n",
      "2. **Natural Language Training and Augmentation with Large Language Models (US20240346254A1)**: This invention focuses on improving natural language generation systems by using large language models both for training and augmentation. It describes a process where an LLM processes training data to produce outputs that a smaller natural language generation system mimics and iteratively improves upon through evaluation and adjustment. Additionally, the LLM can augment smaller models by providing external information and contextual frameworks, thereby enhancing the smaller model's performance on natural language tasks. This technique enables more efficient training and better output quality without solely relying on large datasets.\n",
      "\n",
      "3. **Visual Dialogue Model Training (US11562147)**: This invention relates to training visual dialogue models that can engage in meaningful conversations about visual content. The novelty lies in training models that operate effectively in both discriminative and generative settings without requiring large-scale external vision-language datasets. This facilitates improved performance in visual dialogue tasks and supports various learning strategies and fine-tuning methods, advancing transfer learning research in this area.\n",
      "\n",
      "4. **Language-Based Learning and Reasoning (US11989527)**: This invention presents a novel approach where learning is represented not as statistical model weights but as concepts and ideas expressed in natural language (using a language called UL). The system learns from natural language conversations and reasoning chains, storing this knowledge in memory to improve performance and enable reasoning and explanation in human language. This contrasts with traditional machine learning by enabling models to reason, explain, and converse more naturally and transparently.\n",
      "\n",
      "In summary, the key novelties across these inventions are the use of large language models to generate and augment training data for domain-specific dialogue systems, iterative training methods that improve smaller models via LLM evaluation, training visual dialogue models without massive external datasets, and a language-based learning framework that enables reasoning and explainability beyond conventional statistical learning.\n",
      "\n",
      "\n",
      "RETRIEVED CHUNKS (for debugging):\n",
      "- US20240185001A1 chunk 0 (sim=0.575)\n",
      "- US20240185001A1 chunk 5 (sim=0.537)\n",
      "- US20240346254A1 chunk 0 (sim=0.530)\n",
      "- US11562147 chunk 4 (sim=0.524)\n",
      "- US11989527 chunk 85 (sim=0.521)\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the main novelty of these inventions related to language model training or dialogue systems?\"\n",
    "\n",
    "answer, retrieved = rag_answer(\n",
    "    question,\n",
    "    embed_model,\n",
    "    nn_index,\n",
    "    embeddings,\n",
    "    chunks,\n",
    "    client,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    top_k=5,\n",
    ")\n",
    "\n",
    "print(\"QUESTION:\")\n",
    "print(question)\n",
    "print(\"\\nANSWER:\")\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n\\nRETRIEVED CHUNKS (for debugging):\")\n",
    "for r in retrieved:\n",
    "    print(f\"- {r['patent_id']} chunk {r['chunk_index']} (sim={r['score']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b63f8e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RETRIEVED CHUNKS:\n",
      "- US20240185001A1 | chunk 0 | sim=0.575\n",
      "US 20240185001A1 (19) United States (12) Patent Application Publication Nagaraju et al. (54) DATASET GENERATION USING LARGE LANGUAGE MODELS (71) Applicant: NVIDIA Corporation, Santa Clara, CА (US) (72) Inventors: Divija Nagaraju, Mountain View, СА (US); Christopher Parisien, Toronto (CA) (21) Appl.  ...\n",
      "\n",
      "- US20240185001A1 | chunk 5 | sim=0.537\n",
      "that were previously performed by humans. In addition to designing efficient and effective machine-learning model (MLM) architectures, the successful deployment or application of the MLMs also depends heavily on the training techniques employed. For example, training an MLM to perform a specific tas ...\n",
      "\n",
      "- US20240346254A1 | chunk 0 | sim=0.530\n",
      "(19) United States (12) Patent Application Publication LIU et al. (54) NATURAL LANGUAGE TRAINING AND/OR AUGMENTATION WITH LARGE LANGUAGE MODELS (71) Applicant: MICROSOFT TECHNOLOGY LICENSING, LLC, Redmond, WA (US) (72) Inventors: Yang LIU, Bellevue, WA (US); Yichong XU, Bellevue, WA (US); Dan ITER,  ...\n",
      "\n",
      "- US11562147 | chunk 4 | sim=0.524\n",
      "both discriminative and generative settings whereas the prior approaches in visual dialogue are restricted to only pretraining with discriminative settings, and 2) not requiring to pretrain on large-scale external vision-language datasets as opposed to the prior approaches with inferior performance  ...\n",
      "\n",
      "- US11989527 | chunk 85 | sim=0.521\n",
      "to be detrimental from this test process can be ignored for production use. Learning Examples of the present invention including examples implementing any of the applications described herein or other applications can learn, representing what they have learned in UL (or similar) and then utilising t ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nRETRIEVED CHUNKS:\")\n",
    "for r in retrieved:\n",
    "    print(f\"- {r['patent_id']} | chunk {r['chunk_index']} | sim={r['score']:.3f}\")\n",
    "    print(r['text'][:300], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8118113",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m n_docs = \u001b[38;5;28mlen\u001b[39m(\u001b[43mdocs\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDocuments:\u001b[39m\u001b[33m\"\u001b[39m, n_docs)\n\u001b[32m      4\u001b[39m all_chunks = []\n",
      "\u001b[31mNameError\u001b[39m: name 'docs' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b93f01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
